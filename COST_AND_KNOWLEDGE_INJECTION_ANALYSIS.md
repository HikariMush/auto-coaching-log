# コスト分析 & 重要思考の供与戦略

## 📊 最適化コストの見積もり

### 現在の設定

[`optimize_coach.py`](src/utils/optimize_coach.py:246-251)より：
```python
optimizer = dspy.Teleprompter(
    metric=metric,
    trainset=trainset,
    valset=trainset[:len(trainset)//5],
    num_trials=100,  # ← これがコストを決定
    seed=42
)
```

### コスト計算

#### 前提条件
- トレーニングデータ: 30件
- 試行回数: 100回
- 使用モデル: Gemini 2.5 Flash（デフォルト）
- 1質問あたりの推論: 分類(Reflex) + 回答生成(Thinking) = 2回

#### 詳細計算

**ケース1: 最小コスト（最適化が早期に収束）**
```
実際の試行数: 30-50回
各試行のトークン数:
  - 入力: 平均500 tokens（質問 + コンテクスト + プロンプト）
  - 出力: 平均800 tokens（回答）
  
総トークン数:
  50試行 × 30質問 × 2推論 × 1300 tokens = 3,900,000 tokens
  
Gemini 2.5 Flash料金:
  - Input: $0.00001875/1K tokens
  - Output: $0.000075/1K tokens
  
コスト:
  Input: (3,900K tokens × 50%) × $0.00001875 = $0.037
  Output: (3,900K tokens × 50%) × $0.000075 = $0.146
  合計: $0.18 - $0.30
```

**ケース2: 標準コスト（num_trials=100を完走）**
```
総トークン数:
  100試行 × 30質問 × 2推論 × 1300 tokens = 7,800,000 tokens

コスト:
  Input: (7,800K × 50%) × $0.00001875 = $0.073
  Output: (7,800K × 50%) × $0.000075 = $0.292
  合計: $0.37 - $0.50
```

**ケース3: 最大コスト（Thinking Model使用 + 長文回答）**
```
モデル: Gemini 2.5 Pro（より賢いが高コスト）
  - Input: $0.00015/1K tokens（Flash比8倍）
  - Output: $0.0006/1K tokens（Flash比8倍）

長文回答: 平均2000 tokens

総トークン数:
  100試行 × 30質問 × 2推論 × 2500 tokens = 15,000,000 tokens

コスト:
  Input: (15,000K × 40%) × $0.00015 = $0.90
  Output: (15,000K × 60%) × $0.0006 = $5.40
  合計: $6.30 - $8.00
```

### 結論：予想コスト範囲

| シナリオ | コスト範囲 | 発生条件 |
|---------|----------|---------|
| 最小 | **$0.20 - $0.50** | Flash使用、早期収束 |
| 標準 | **$0.50 - $2.00** | Flash使用、100試行完走 |
| 最大 | **$6.00 - $10.00** | Pro使用、100試行完走 |

**推奨**: 初回は`num_trials=30`で試して、コストと品質のバランスを確認

---

## 🧠 重要思考の供与：戦略比較

### ユーザー提案の分析

**提案内容**:
> 重みが大きい思考を提示 → AIが類似性の高い事項を列挙 → それぞれとの関連性についてAIが質問 → ベクトルデータ構築

**評価**:

#### メリット
1. **対話的な知識抽出**: ユーザーの暗黙知を引き出せる
2. **文脈の明確化**: AIが質問することで、思考の関連性が明確になる
3. **ベクトル空間の密度向上**: 関連事項が多く生成されるため、検索精度が上がる

#### デメリット
1. **ユーザー負担が高い**: 1つの思考について複数の質問に答える必要
2. **時間コスト**: 対話が長くなる可能性
3. **一貫性の課題**: 対話中に思考がブレる可能性

### 代替手法との比較

#### 方法A: 対話的思考拡張（ユーザー提案）

**フロー**:
```
1. ユーザー: 「崖外での復帰阻止は、相手の復帰ルートを読むことが最重要」
2. AI: 「この思考と関連性が高い概念を検出しました：
        - 復帰タイミングの予測
        - 復帰技の発生フレーム
        - 自分の復帰力とのリスクバランス
        質問: それぞれとの関連性を1-5で評価してください」
3. ユーザー: 「1は5, 2は3, 3は4」
4. AI: 重み付きベクトルとしてPineconeに保存
```

**実装コスト**: 中（対話システムの構築が必要）  
**ユーザー負担**: 高（各思考につき5-10分）  
**学習効率**: ★★★★☆（関連性が明確）  
**拡張性**: ★★★★★（対話で無限に拡張可能）

---

#### 方法B: 構造化思考テンプレート

**フロー**:
```
テンプレート例:
---
思考: 崖外での復帰阻止の判断基準
├─ 前提条件: [相手キャラの復帰力, 自分の復帰力, ストック差]
├─ 判断要素: [相手の復帰ルート, 復帰技の発生, 自分の技のリーチ]
├─ リスク: [自分が復帰できなくなる, 相手に反撃される]
├─ リターン: [早期撃墜, ストック有利]
└─ 推奨行動: [安全な位置から牽制, 確実に当たる場面のみ深追い]
---

ユーザーが穴埋め → 自動的にベクトル化
```

**実装コスト**: 低（テンプレートの定義のみ）  
**ユーザー負担**: 中（穴埋め形式で5分程度）  
**学習効率**: ★★★★★（構造化されているためDSPyが学習しやすい）  
**拡張性**: ★★★☆☆（テンプレート追加で拡張）

---

#### 方法C: Few-Shot思考学習

**フロー**:
```
模範的な思考プロセス5-10個を提示:

例1:
Q: 「マリオの空前をガードした時の選択肢は？」
思考プロセス:
1. フレームデータ確認（着地硬直9F → ガード側+9F有利）
2. 確定反撃の発生確認（掴みF6 → 確定）
3. 相手の選択肢予測（ガード継続 or 回避 or ジャンプ）
4. リスクリターン評価（掴みは安定、上強はダメージ高いが非確定）
5. 推奨行動：掴みを最優先、読み合いなら上強

DSPyがこのパターンを学習 → 新しい質問に適用
```

**実装コスト**: 低（模範例をDSPyのfew-shotに登録）  
**ユーザー負担**: 低（初回のみ模範例を作成）  
**学習効率**: ★★★★★（DSPyの得意分野）  
**拡張性**: ★★★★☆（模範例を追加するだけ）

---

#### 方法D: メタ思考の事前インジェクション

**フロー**:
```
Pineconeに「思考フレームワーク」を特別なメタデータとして保存:

{
  "id": "meta_framework_risk_return",
  "type": "思考フレームワーク",
  "title": "リスクリターン分析",
  "content": "技を出す前に必ず以下を評価せよ：
              1. 当たった場合のリターン（ダメージ, %, 撃墜可能性）
              2. 外した/ガードされた場合のリスク（確定反撃, 不利フレーム）
              3. 状況（相手の%, 自分の%, ストック差）
              4. 期待値 = (リターン × 当たる確率) - (リスク × 外す確率)",
  "priority": 10,  # 検索時に高優先度
  "always_include": true  # 全ての回答に含める
}

検索時: 通常の検索 + メタ思考を強制的に含める
```

**実装コスト**: 中（Pinecone検索ロジックの拡張）  
**ユーザー負担**: 低（事前に定義するだけ）  
**学習効率**: ★★★★☆（常に参照されるため一貫性が高い）  
**拡張性**: ★★★☆☆（メタデータ追加で拡張）

---

### 総合評価

| 方法 | 実装 | ユーザー負担 | 学習効率 | 拡張性 | 総合スコア |
|-----|------|------------|---------|--------|----------|
| A. 対話的拡張（提案） | ★★★☆☆ | ★★☆☆☆ | ★★★★☆ | ★★★★★ | **16/20** |
| B. テンプレート | ★★★★★ | ★★★★☆ | ★★★★★ | ★★★☆☆ | **18/20** |
| C. Few-Shot学習 | ★★★★★ | ★★★★★ | ★★★★★ | ★★★★☆ | **19/20** ⭐ |
| D. メタ思考注入 | ★★★☆☆ | ★★★★★ | ★★★★☆ | ★★★☆☆ | **16/20** |

---

## 🎯 推奨実装戦略

### フェーズ1: Few-Shot思考学習（即座に開始可能）

**理由**:
- DSPyの得意分野（demonstration-based learning）
- ユーザー負担が最小
- 実装コストが低い

**実装方法**:

1. **模範的な思考プロセスを5-10個作成**

```python
# src/brain/思考_examples.py
EXEMPLARY_THINKING = [
    {
        "question": "マリオの空前をガードした時の選択肢は？",
        "thinking_process": """
1. フレームデータ確認
   - 発生3F + 着地硬直9F = ガード側+9F有利
   
2. 確定反撃の確認
   - 掴み（F6）: 確定
   - 弱攻撃（F2-3）: 確定
   - 上強（F5）: 確定
   
3. 相手の選択肢予測
   - ガード継続（安全策）
   - 回避（リスク）
   - ジャンプ（逃げ）
   
4. リスクリターン評価
   - 掴み: リスク低、リターン中（投げダメージ + 展開有利）
   - 上強: リスク中、リターン高（コンボ始動）
   
5. 推奨行動
   最優先: 掴み（確実かつ安全）
   読み合い: 上強（相手がガード継続している場合）
        """,
        "answer": "ガードした側は+9F有利なので、掴み（F6）が確定します..."
    },
    # ... 他の例
]
```

2. **DSPyのFew-Shot機能に統合**

```python
# src/brain/core.py
from src.brain.思考_examples import EXEMPLARY_THINKING

class CoachAnswer(dspy.Signature):
    """
    あなたは経験豊富なスマブラコーチです。
    以下の模範的な思考プロセスを参考に、同様の論理展開で回答してください。
    
    === 模範例 ===
    {EXEMPLARY_THINKING[0]['thinking_process']}
    
    === あなたの回答 ===
    同様の論理展開（フレーム確認 → 確定反撃 → 選択肢予測 → 評価 → 推奨）で回答せよ。
    """
    ...
```

**コスト**: $0（実装のみ、API呼び出し増加なし）  
**効果**: 思考プロセスの一貫性が即座に向上

---

### フェーズ2: 構造化思考テンプレート（中期）

**理由**:
- Few-Shotで基礎が確立された後、より高度な思考を追加
- ユーザーが穴埋め形式で貢献しやすい

**実装方法**:

1. **Discordに`/add_思考`コマンドを追加**

```python
@bot.tree.command(name="add_思考", description="重要な思考プロセスを追加")
@app_commands.describe(
    title="思考の名前（例: 復帰阻止の判断基準）",
    前提条件="この思考を適用する前提",
    判断要素="判断に必要な要素",
    リスク="この行動のリスク",
    リターン="この行動のリターン",
    推奨行動="具体的な推奨行動"
)
async def add_思考(...):
    # テンプレートに沿って保存
    # Pineconeに高優先度で登録
```

**コスト**: 実装2-3時間  
**効果**: ユーザーが継続的に思考を追加できる仕組み

---

### フェーズ3: 対話的思考拡張（長期・オプション）

**理由**:
- フェーズ1, 2で基礎が確立された後の拡張機能
- より複雑な思考の抽出に有効

**実装方法**:

```python
@bot.tree.command(name="expand_思考", description="AIと対話して思考を拡張")
async def expand_思考(interaction, 思考内容: str):
    # 1. AIが関連概念を抽出
    related_concepts = ai.extract_related_concepts(思考内容)
    
    # 2. ユーザーに関連性を質問
    await interaction.followup.send(
        f"以下の概念との関連性を評価してください（1-5）:\n"
        f"{'\n'.join(related_concepts)}"
    )
    
    # 3. 回答を元に重み付きベクトル生成
    # 4. Pineconeに保存
```

**コスト**: 実装5-8時間 + API使用料（1思考あたり$0.01程度）  
**効果**: 暗黙知の抽出、ベクトル空間の密度向上

---

## 💡 最終推奨

### 即座に実装すべき: **方法C（Few-Shot思考学習）**

**理由**:
1. 実装コスト最小（1-2時間）
2. API追加コストなし
3. DSPyとの相性が最高
4. 即座に効果が出る

**手順**:
1. [`EXEMPLARY_THINKING.md`](EXEMPLARY_THINKING.md)を作成（ユーザーと協力）
2. [`CoachAnswer`](src/brain/core.py) Signatureに統合
3. 5個の模範例から開始、段階的に追加

### 中期的に追加: **方法B（構造化テンプレート）**

**理由**:
- ユーザーが継続的に貢献しやすい
- フェーズ1の効果を見てから判断できる

### 長期的オプション: **方法A（対話的拡張）**

**理由**:
- 基礎が確立された後の拡張機能
- より高度な思考の抽出に有効

---

## 📝 次のアクション

1. **コスト確認**: `num_trials=30`で初回最適化を実行（予想コスト: $0.20-$0.50）
2. **思考例の作成**: ユーザーと協力して模範的な思考プロセス5個を作成
3. **Few-Shot実装**: CoachAnswer Signatureに統合（1-2時間）
4. **効果測定**: 回答の論理性と一貫性を確認

必要であれば、思考例の作成支援やFew-Shot実装を行います。
