import os
import time
import json
import requests
from google import genai
from google.genai import types

# --- Config ---
SOURCE_LOG_DB_ID = "2e01bc8521e380ffaf28c2ab9376b00d"   # ãƒ­ã‚°DB
TARGET_THEORY_DB_ID = "2e21bc8521e38029b8b1d5c4b49731eb"  # Theory DB

NOTION_TOKEN = os.getenv("NOTION_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# --- Model Resolver ---
def resolve_best_model():
    client = genai.Client(api_key=GEMINI_API_KEY)
    candidates = [
        "gemini-2.5-flash",       # â˜…æœ€å„ªå…ˆ
        "gemini-2.0-flash-exp",   # æ¬¡ç‚¹
        "gemini-1.5-flash",       # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        "gemini-1.5-pro"
    ]
    print("ğŸ’ Resolving Best Gemini Model...", flush=True)
    for model in candidates:
        try:
            client.models.generate_content(model=model, contents="Test")
            print(f"âœ… Model Resolved: {model}", flush=True)
            return model
        except Exception: continue
    print("âš ï¸ All checks failed. Fallback to 'gemini-1.5-flash'", flush=True)
    return "gemini-1.5-flash"

ACTIVE_MODEL_ID = None

# --- Notion API Helpers ---
def get_page_content(page_id):
    all_text = ""
    has_more = True
    start_cursor = None
    while has_more:
        url = f"https://api.notion.com/v1/blocks/{page_id}/children?page_size=100"
        if start_cursor: url += f"&start_cursor={start_cursor}"
        try:
            res = requests.get(url, headers=HEADERS)
            if res.status_code != 200: break
            data = res.json()
            for block in data.get("results", []):
                btype = block.get("type")
                if not btype or "rich_text" not in block.get(btype, {}): continue
                text_list = block[btype].get("rich_text", [])
                line = "".join([t.get("text", {}).get("content", "") for t in text_list])
                if line: all_text += line + "\n"
            has_more = data.get("has_more", False)
            start_cursor = data.get("next_cursor")
        except: break
    return all_text

def mark_log_as_processed(page_id):
    """ãƒ­ã‚°å´ã®ã€AIå‡¦ç†æ¸ˆã¿ã€ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ONã«ã™ã‚‹"""
    url = f"https://api.notion.com/v1/pages/{page_id}"
    payload = {"properties": {"AIå‡¦ç†æ¸ˆã¿": {"checkbox": True}}}
    try:
        requests.patch(url, headers=HEADERS, json=payload)
        print(f"   â˜‘ï¸ Marked as processed: {page_id}")
    except Exception as e:
        print(f"   âš ï¸ Failed to mark processed: {e}")

def text_to_blocks(text):
    blocks = []
    for line in text.split('\n'):
        if not line.strip(): 
            blocks.append({"object":"block", "type":"paragraph", "paragraph":{"rich_text":[]}})
            continue
        ct = line.replace('**', '')[:1900]
        if line.startswith('### '):
            blocks.append({"object":"block", "type":"heading_3", "heading_3":{"rich_text":[{"text":{"content":ct[4:]}}]}})
        elif line.startswith('## '):
            blocks.append({"object":"block", "type":"heading_2", "heading_2":{"rich_text":[{"text":{"content":ct[3:]}}]}})
        elif line.startswith('- '):
            blocks.append({"object":"block", "type":"bulleted_list_item", "bulleted_list_item":{"rich_text":[{"text":{"content":ct[2:]}}]}})
        else:
            blocks.append({"object":"block", "type":"paragraph", "paragraph":{"rich_text":[{"text":{"content":ct}}]}})
    return blocks

# --- Gemini Logic ---
def generate_theories(log_text):
    client = genai.Client(api_key=GEMINI_API_KEY)
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©ï¼ˆæœ€æ–°ç‰ˆï¼‰
    prompt = f"""
    ã‚ãªãŸã¯ã‚¹ãƒãƒ–ãƒ©ã®ç†è«–æ§‹ç¯‰AIã§ã™ã€‚å…¥åŠ›ã•ã‚ŒãŸã‚³ãƒ¼ãƒãƒ³ã‚°ãƒ­ã‚°ã‹ã‚‰ã€Œä¸€èˆ¬çš„æ”»ç•¥ç†è«–ã€ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    
    ã€æŠ½å‡ºã‚«ãƒ†ã‚´ãƒªã®å®šç¾©ã€‘
    ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚æ›–æ˜§ãªå ´åˆã¯ã‚ˆã‚Šå…·ä½“çš„ãªæ–¹ã‚’é¸ã³ã€å®‰æ˜“ã«ã€Œç«‹ã¡å›ã‚Šã€ã«å…¥ã‚Œãªã„ã“ã¨ã€‚
    - å¾©å¸°é˜»æ­¢ (Edgeguarding)
    - å¾©å¸° (Recovery)
    - å´–ä¸ŠãŒã‚Š (Ledge Option)
    - å´–ç‹©ã‚Š (Ledge Trapping)
    - ç«‹ã¡å›ã‚Š (Neutral/Footsies)
    - æ€è€ƒ (Thinking/Decision Making)
    - ãƒ¡ãƒ³ã‚¿ãƒ« (Mental)
    - æ’ƒå¢œ (Kill Confirm/KO)
    - æ’ƒå¢œæ‹’å¦ (Survival)
    - ãã®ä»– (Other)

    ã€é‡è¦ã€‘
    1. "detail" ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ã€Notionã®ãƒšãƒ¼ã‚¸æœ¬æ–‡ã«ãªã‚Šã¾ã™ã€‚Markdownå½¢å¼ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
    2. "characters"ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åï¼‰ã¯ã€å¿…ãšã€Œã‚¹ãƒãƒ–ãƒ©SPã®æ—¥æœ¬èªæ­£å¼åç§°ã€ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    3. ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    Format (JSON Array):
    [
      {{
        "theory_name": "ã‚¿ã‚¤ãƒˆãƒ« (30æ–‡å­—ä»¥å†…)",
        "category": "å´–ç‹©ã‚Š", 
        "importance": "S",
        "characters": ["ã‚¯ãƒ©ã‚¦ãƒ‰", "å…¨èˆ¬"],
        "tags": ["ã‚¸ãƒ£ãƒ³ãƒ—ä¸ŠãŒã‚Š", "ç©ºå¾Œ"],
        "abstract": "ä¸€è¦§è¡¨ç¤ºç”¨ã®3è¡Œè¦ç´„",
        "detail": "### è§£èª¬\\nã“ã“ã«è©³ç´°ãªç†è«–ã‚’æ›¸ãã€‚", 
        "source_context": "å…ƒãƒ­ã‚°ã‹ã‚‰ã®å¼•ç”¨æŠœç²‹"
      }}
    ]

    Log: {log_text[:20000]}
    """
    try:
        res = client.models.generate_content(
            model=ACTIVE_MODEL_ID, 
            contents=prompt, 
            config=types.GenerateContentConfig(response_mime_type="application/json")
        )
        return json.loads(res.text)
    except Exception as e:
        print(f"Gemini Error: {e}")
        return []

# --- Save Logic ---
def save_theory(theory, log_id):
    props = {
        "Theory Name": {"title": [{"text": {"content": theory.get("theory_name", "Untitled")}}]},
        "Category": {"select": {"name": theory.get("category", "ãã®ä»–")}},
        "Importance": {"select": {"name": theory.get("importance", "B (çŠ¶æ³é™å®š)")}},
        "Abstract": {"rich_text": [{"text": {"content": theory.get("abstract", "")}}]},
        "Source Log": {"relation": [{"id": log_id}]}, # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        "Verification": {"status": {"name": "Draft"}},
        "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼": {"multi_select": [{"name": c} for c in theory.get("characters", [])]},
        "Tags": {"multi_select": [{"name": t} for t in theory.get("tags", [])]}
    }
    
    children = []
    if "source_context" in theory:
        children.append({
            "object":"block", "type":"callout", 
            "callout":{
                "rich_text":[{"text":{"content": f"Source Context:\n{theory['source_context'][:1900]}"}}],
                "icon": {"emoji": "ğŸ’¡"}
            }
        })
    children.extend(text_to_blocks(theory.get("detail", "")))

    try:
        res = requests.post(
            "https://api.notion.com/v1/pages", 
            headers=HEADERS, 
            json={"parent": {"database_id": TARGET_THEORY_DB_ID}, "properties": props, "children": children}
        )
        if res.status_code == 200:
            print(f"âœ… Saved: {theory.get('theory_name')}")
        else:
            print(f"âŒ Save Failed ({res.status_code}): {res.text}")
    except Exception as e:
        print(f"âŒ Network Error: {e}")

# --- Main (Bulk Mode) ---
def main():
    global ACTIVE_MODEL_ID
    print("--- Generalization Started (Bulk Mode) ---")
    ACTIVE_MODEL_ID = resolve_best_model()

    has_more = True
    
    while has_more:
        # æœªå‡¦ç†ãƒ­ã‚°ã‚’50ä»¶ãšã¤å–å¾—
        query = {
            "filter": {
                "property": "AIå‡¦ç†æ¸ˆã¿",
                "checkbox": {
                    "equals": False
                }
            },
            "page_size": 50, 
            "sorts": [{"property": "æ—¥ä»˜", "direction": "descending"}]
        }
        
        try:
            res = requests.post(f"https://api.notion.com/v1/databases/{SOURCE_LOG_DB_ID}/query", headers=HEADERS, json=query)
            logs = res.json().get("results", [])
        except Exception as e:
            print(f"âŒ Failed to fetch logs: {e}")
            break
        
        if not logs:
            print("â„¹ï¸ No more unprocessed logs found. System sleeping.")
            has_more = False
            break

        print(f"ğŸ” Found batch of {len(logs)} logs. Processing...")

        for log in logs:
            print(f"\nProcessing Log: {log['id']}")
            content = get_page_content(log["id"])
            
            # çŸ­ã™ãã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼†å‡¦ç†æ¸ˆã¿ã«
            if len(content) < 50: 
                print("   âš ï¸ Content too short. Marking as processed.")
                mark_log_as_processed(log["id"])
                continue
            
            theories = generate_theories(content)
            
            # ç†è«–ãŒå‡ºãªãã¦ã‚‚å‡¦ç†æ¸ˆã¿ã«ï¼ˆãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰
            if not theories:
                 print("   âš ï¸ No theories extracted. Marking as processed.")
                 mark_log_as_processed(log["id"])
                 continue

            for t in theories:
                save_theory(t, log["id"])
                time.sleep(1) # Notion API Rate Limit
                
            mark_log_as_processed(log["id"])
            
        time.sleep(2) # ãƒãƒƒãƒé–“ã®ä¼‘æ†©

if __name__ == "__main__":
    main()
