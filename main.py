import os
import sys
import subprocess
import time
import json
import logging
import re
import zipfile
import shutil
from datetime import datetime

# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå¼·åˆ¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
try:
    import requests
    import google.generativeai as genai
    from pydub import AudioSegment
except ImportError:
    print("ğŸ”„ Installing core libraries...", flush=True)
    subprocess.check_call([
        sys.executable, "-m", "pip", "install", "--upgrade", 
        "requests", "google-generativeai>=0.8.3", "pydub",
        "google-api-python-client", "google-auth"
    ])
    import requests
    import google.generativeai as genai
    from pydub import AudioSegment

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

# --- æœ€çµ‚è¨­å®š ---
FINAL_CONTROL_DB_ID = "2b71bc8521e380868094ec506b41f664" 

# --- åˆæœŸåŒ– ---
TEMP_DIR = "downloads"
if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
os.makedirs(TEMP_DIR)

if os.getenv("GCP_SA_KEY"):
    with open("service_account.json", "w") as f:
        f.write(os.getenv("GCP_SA_KEY"))

def sanitize_id(raw_id):
    if not raw_id: return None
    match = re.search(r'([a-fA-F0-9]{32})', str(raw_id).replace("-", ""))
    if match: return match.group(1)
    return None

try:
    NOTION_TOKEN = os.getenv("NOTION_TOKEN")
    HEADERS = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28" 
    }
    
    CONTROL_CENTER_ID = sanitize_id(FINAL_CONTROL_DB_ID)
    INBOX_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID")
    
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    SCOPES = ['https://www.googleapis.com/auth/drive']
    creds = service_account.Credentials.from_service_account_file("service_account.json", scopes=SCOPES)
    drive_service = build('drive', 'v3', credentials=creds)
    
except Exception as e:
    print(f"âŒ Setup Critical Error: {e}", flush=True)
    exit(1)

# --- Notion API Helpers ---

def notion_query_database(db_id, query_filter):
    url = f"https://api.notion.com/v1/databases/{db_id}/query"
    try:
        res = requests.post(url, headers=HEADERS, json=query_filter)
        res.raise_for_status()
        return res.json()
    except Exception as e:
        print(f"âš ï¸ Notion Query Error: {e}")
        return None

def notion_create_page(parent_db_id, properties, children):
    url = "https://api.notion.com/v1/pages"
    # ãƒ–ãƒ­ãƒƒã‚¯æ•°ãŒå¤šã™ãã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ã€100ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«åˆ†å‰²ã—ã¦è¿½åŠ ã™ã‚‹å‡¦ç†ãŒå¿…è¦ã ãŒ
    # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«æœ€åˆã®100ãƒ–ãƒ­ãƒƒã‚¯ã¾ã§ã¨ã™ã‚‹ï¼ˆã¾ãŸã¯åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ï¼‰
    
    # æœ€åˆã®ä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ (Properties + æœ€åˆã®Children)
    initial_children = children[:90] # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
    remaining_children = children[90:]
    
    payload = {"parent": {"database_id": parent_db_id}, "properties": properties, "children": initial_children}
    
    try:
        res = requests.post(url, headers=HEADERS, json=payload)
        res.raise_for_status()
        page_data = res.json()
        page_id = page_data['id']
        
        # æ®‹ã‚Šã®ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã€Append APIã§è¿½åŠ 
        if remaining_children:
            append_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
            # 100å€‹ãšã¤ãƒ«ãƒ¼ãƒ—
            for i in range(0, len(remaining_children), 100):
                chunk = remaining_children[i:i+100]
                requests.patch(append_url, headers=HEADERS, json={"children": chunk})
                
        return page_data
    except Exception as e:
        print(f"âŒ Create Page Error: {e}")
        try: print(f"Detail: {res.text}")
        except: pass
        raise e

def get_student_target_id(student_name):
    print(f"ğŸ” Looking up student: '{student_name}'", flush=True)
    search_filter = {"filter": {"property": "Name", "title": {"contains": student_name}}}
    data = notion_query_database(CONTROL_CENTER_ID, search_filter)
    if not data or not data.get("results"): return None
    target_id_prop = data["results"][0]["properties"].get("TargetID", {}).get("rich_text", [])
    if not target_id_prop: return None
    return sanitize_id(target_id_prop[0]["plain_text"])

# --- Drive & Gemini Helpers ---

def download_file(file_id, file_name):
    request = drive_service.files().get_media(fileId=file_id)
    file_path = os.path.join(TEMP_DIR, file_name)
    with open(file_path, "wb") as fh:
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
    return file_path

def extract_audio_from_zip(zip_path):
    extracted_files = []
    extract_dir = os.path.join(TEMP_DIR, "extracted_" + os.path.basename(zip_path))
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    for root, dirs, files in os.walk(extract_dir):
        for file in files:
            if file.lower().endswith(('.flac', '.mp3', '.aac', '.wav', '.m4a')):
                extracted_files.append(os.path.join(root, file))
    return extracted_files

def mix_audio_files(file_paths):
    if not file_paths: return None
    print(f"ğŸ›ï¸ Mixing {len(file_paths)} tracks...", flush=True)
    try:
        mixed = AudioSegment.from_file(file_paths[0])
        for path in file_paths[1:]:
            mixed = mixed.overlay(AudioSegment.from_file(path))
        output_path = os.path.join(TEMP_DIR, "mixed_session.mp3")
        mixed.export(output_path, format="mp3")
        return output_path
    except Exception as e:
        print(f"âš ï¸ Mixing Error: {e}. Using largest file.", flush=True)
        return max(file_paths, key=os.path.getsize)

def get_available_model_name():
    # â˜…FIX: Flashå›ºå®šï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ & é«˜é€ŸåŒ–ï¼‰
    print("ğŸ” Using Flash model (Efficiency Mode)...", flush=True)
    return 'models/gemini-2.0-flash'

def analyze_audio_auto(file_path):
    model_name = get_available_model_name()
    
    # â˜…FIX: 3éƒ¨æ§‹æˆï¼ˆæ–‡å­—èµ·ã“ã— / è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ / JSONãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’å‡ºåŠ›ã•ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = """
    ã‚ãªãŸã¯**ãƒˆãƒƒãƒ—ãƒ»ã‚¹ãƒãƒ–ãƒ©ã‚¢ãƒŠãƒªã‚¹ãƒˆ**ã§ã™ã€‚
    ã“ã®éŸ³å£°ã¯ã€**ã‚³ãƒ¼ãƒ (Hikari)** ã¨ **ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (ç”Ÿå¾’)** ã®å¯¾è©±ãƒ­ã‚°ã§ã™ã€‚

    ã€æœ€å„ªå…ˆãƒ‰ãƒ¡ã‚¤ãƒ³ç”¨èªã€‘: ã€Œç€åœ°ç‹©ã‚Šã€ã€Œå´–éš›ã€ã€Œå¾©å¸°é˜»æ­¢ã€ã€Œé–“åˆã„ã€ã€Œç¢ºå®šåæ’ƒã€ã€Œãƒ©ã‚¤ãƒ³ç®¡ç†ã€ã€Œãƒ™ã‚¯ãƒˆãƒ«å¤‰æ›´ã€

    ä»¥ä¸‹ã®3ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é †ã«å‡ºåŠ›ã›ã‚ˆã€‚

    ---
    **[RAW_TRANSCRIPTION_START]**
    ä¼šè©±å…¨ä½“ã‚’ã€å¯èƒ½ãªé™ã‚Šè©³ç´°ã«ã€é€èªè¨³ã«è¿‘ã„å½¢ã§æ–‡å­—èµ·ã“ã—ã›ã‚ˆã€‚
    ï¼ˆâ€»å‡ºåŠ›ãŒé€”åˆ‡ã‚Œãªã„ã‚ˆã†ã€ãƒ•ã‚£ãƒ©ãƒ¼ã€Œã‚ãƒ¼ã€ã€Œãˆãƒ¼ã€ãªã©ã¯é©å®œå‰Šé™¤ã—ã¦ã‚ˆã„ãŒã€å†…å®¹ã¯çœç•¥ã™ã‚‹ãªï¼‰
    **[RAW_TRANSCRIPTION_END]**
    ---
    **[DETAILED_REPORT_START]**
    ä¼šè©±å†…ã§æ‰±ã‚ã‚ŒãŸå„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®**5è¦ç´ **ã‚’ç”¨ã„ã¦è©³ç´°ã«åˆ†è§£ãƒ»è§£èª¬ã›ã‚ˆã€‚
    æ–‡å­—æ•°åˆ¶é™ã¯è¨­ã‘ãªã„ã€‚å…·ä½“çš„ã‹ã¤è«–ç†çš„ã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
    Markdownå½¢å¼ï¼ˆè¦‹å‡ºã—ã‚„ç®‡æ¡æ›¸ãï¼‰ã‚’ä½¿ç”¨ã›ã‚ˆã€‚

    ### ãƒˆãƒ”ãƒƒã‚¯1: [ãƒˆãƒ”ãƒƒã‚¯å]
    * **ç¾çŠ¶**: [å…·ä½“çš„ãªç¾çŠ¶]
    * **èª²é¡Œ**: [ç™ºè¦‹ã•ã‚ŒãŸèª²é¡Œ]
    * **åŸå› **: [æ ¹æœ¬åŸå› ã€èªçŸ¥ãƒã‚¤ã‚¢ã‚¹ãªã©]
    * **æ”¹å–„æ¡ˆ**: [æç¤ºã•ã‚ŒãŸè§£æ±ºç­–]
    * **ã‚„ã‚‹ã“ã¨**: [å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³]

    ### ãƒˆãƒ”ãƒƒã‚¯2: [ãƒˆãƒ”ãƒƒã‚¯å]
    ...ï¼ˆä»¥é™ã€ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚‹é™ã‚Šç¹°ã‚Šè¿”ã™ï¼‰
    **[DETAILED_REPORT_END]**
    ---
    **[JSON_START]**
    ä»¥ä¸‹ã®JSONãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¨˜è¿°ã›ã‚ˆã€‚
    {
      "student_name": "ç”Ÿå¾’ã®åå‰ï¼ˆä¾‹: ã‚‰ãã´, ãƒˆãƒ­ãƒ”ã‚¦ã‚¹, Unknownï¼‰",
      "date": "YYYY-MM-DD (ä¸æ˜ãªã‚‰Today)",
      "next_action": "æœ€ã‚‚é‡è¦ãªæ¬¡å›ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ1è¡Œï¼‰"
    }
    **[JSON_END]**
    """

    try:
        print(f"ğŸ§  Analyzing with {model_name}...", flush=True)
        model = genai.GenerativeModel(model_name)
        audio_file = genai.upload_file(file_path)
        while audio_file.state.name == "PROCESSING": time.sleep(2); audio_file = genai.get_file(audio_file.name)
        
        # å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æœ€å¤§åŒ– (Flashã¯8192ã¾ã§å‡ºã›ã‚‹)
        response = model.generate_content(
            [prompt, audio_file],
            generation_config=genai.types.GenerationConfig(max_output_tokens=8192)
        )
        text = response.text.strip()
        
        try: genai.delete_file(audio_file.name)
        except: pass

        # --- Parsing ---
        # 1. Raw Transcript
        raw_match = re.search(r'\[RAW_TRANSCRIPTION_START\](.*?)\[RAW_TRANSCRIPTION_END\]', text, re.DOTALL)
        raw_text = raw_match.group(1).strip() if raw_match else "Transcript Error"

        # 2. Detailed Report
        report_match = re.search(r'\[DETAILED_REPORT_START\](.*?)\[DETAILED_REPORT_END\]', text, re.DOTALL)
        report_text = report_match.group(1).strip() if report_match else "Report Error"

        # 3. JSON Metadata
        json_match = re.search(r'\[JSON_START\](.*?)\[JSON
