import sys
import subprocess
import os
import time
import json
import shutil
import glob
import re
from datetime import datetime

# --- 0. Êñ∞SDK„ÅÆÂº∑Âà∂Â∞éÂÖ• (Migration) ---
# Êóß„É©„Ç§„Éñ„É©„É™(google-generativeai)„ÇíÊç®„Å¶„ÄÅÊñ∞ÂÖ¨ÂºèSDK(google-genai)„ÇíÂ∞éÂÖ•
try:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "google-genai"])
    subprocess.check_call([sys.executable, "-m", "pip", "install", "groq"]) # Âøµ„ÅÆ„Åü„ÇÅ
except: pass

# --- Libraries ---
import requests
# ‚òÖ Êñ∞„Åó„ÅÑSDK„ÅÆ„Ç§„É≥„Éù„Éº„Éà
from google import genai 
from groq import Groq
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import zipfile

# --- Configuration ---
FINAL_CONTROL_DB_ID = "2b71bc8521e380868094ec506b41f664"
FINAL_FALLBACK_DB_ID = "2b71bc8521e38018a5c3c4b0c6b6627c"
TEMP_DIR = "temp_workspace"
CHUNK_LENGTH = 900  # 15ÂàÜ

# --- 1. ÂàùÊúüÂåñ & Êé•Á∂ö„ÉÜ„Çπ„Éà (Setup) ---
def setup_env():
    if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
    os.makedirs(TEMP_DIR)
    if os.getenv("GCP_SA_KEY"):
        with open("service_account.json", "w") as f:
            f.write(os.getenv("GCP_SA_KEY"))

setup_env()

try:
    # Groq Client
    groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
    
    # ‚òÖ Gemini Client (Êñ∞SDK‰ªïÊßò)
    # REST/gRPC„ÅÆÁÆ°ÁêÜ„ÅØÊñ∞SDK„ÅåÊúÄÈÅ©Âåñ„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ„Éá„Éï„Ç©„É´„ÉàË®≠ÂÆö„ÅßÂàùÊúüÂåñ„Åô„Çã
    gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    
    print("ü©∫ Connectivity Test (New SDK)...", flush=True)
    try:
        # Êñ∞SDK„Åß„ÅÆÁñéÈÄöÁ¢∫Ë™ç
        test_resp = gemini_client.models.generate_content(
            model='gemini-1.5-flash',
            contents='Hello'
        )
        print(f"‚úÖ Connection OK: {test_resp.text[:20]}...", flush=True)
    except Exception as e:
        print(f"‚ö†Ô∏è Connection Warning: {e}")
        # Êñ∞SDK„Åß„ÇÇ„Ç≥„Ç±„ÇãÂ†¥Âêà„ÅØ„ÄÅAPI„Ç≠„ÉºËá™‰Ωì„ÅÆÊ®©ÈôêË®≠ÂÆö„ÇíÁñë„ÅÜÂøÖË¶Å„Åå„ÅÇ„Çã„Åå„ÄÅ„Åæ„Åö„ÅØÈÄ≤„ÇÅ„Çã
        
    NOTION_TOKEN = os.getenv("NOTION_TOKEN")
    HEADERS = {"Authorization": f"Bearer {NOTION_TOKEN}", "Content-Type": "application/json", "Notion-Version": "2022-06-28"}
    creds = service_account.Credentials.from_service_account_file("service_account.json", scopes=['https://www.googleapis.com/auth/drive'])
    drive_service = build('drive', 'v3', credentials=creds)
    INBOX_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID")
    
except Exception as e:
    print(f"‚ùå Init Error: {e}"); sys.exit(1)

def sanitize_id(raw_id):
    if not raw_id: return None
    match = re.search(r'([a-fA-F0-9]{32})', str(raw_id).replace("-", ""))
    return match.group(1) if match else None

# --- 2. Èü≥Â£∞„Éë„Ç§„Éó„É©„Ç§„É≥ ---

def mix_audio_ffmpeg(file_paths):
    print(f"üéõÔ∏è Mixing {len(file_paths)} tracks...", flush=True)
    output_path = os.path.abspath(os.path.join(TEMP_DIR, "final_mix.mp3"))
    inputs = []
    for f in file_paths: inputs.extend(['-i', f])
    filter_part = ['-filter_complex', f'amix=inputs={len(file_paths)}:duration=longest'] if len(file_paths) > 1 else []
    cmd = ['ffmpeg', '-y'] + inputs + filter_part + ['-ac', '1', '-b:a', '64k', output_path]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return output_path

def split_audio_ffmpeg(input_path):
    print("üî™ Splitting...", flush=True)
    output_pattern = os.path.join(TEMP_DIR, "chunk_%03d.mp3")
    cmd = ['ffmpeg', '-y', '-i', input_path, '-f', 'segment', '-segment_time', str(CHUNK_LENGTH), '-ac', '1', '-b:a', '64k', output_pattern]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return sorted(glob.glob(os.path.join(TEMP_DIR, "chunk_*.mp3")))

def transcribe_with_groq(chunk_paths):
    full_transcript = ""
    for chunk in chunk_paths:
        if not chunk.endswith(".mp3"): continue
        print(f"üöÄ Groq Transcribing: {os.path.basename(chunk)}", flush=True)
        max_retries = 50
        for attempt in range(max_retries):
            try:
                with open(chunk, "rb") as file:
                    res = groq_client.audio.transcriptions.create(
                        file=(os.path.basename(chunk), file),
                        model="whisper-large-v3", language="ja", response_format="text"
                    )
                full_transcript += res + "\n"
                break 
            except Exception as e:
                err_str = str(e).lower()
                if "429" in err_str or "rate limit" in err_str:
                    wait = 70
                    print(f"‚è≥ Rate Limit. Waiting {wait}s... ({attempt+1}/{max_retries})", flush=True)
                    time.sleep(wait)
                else: raise e
        else: raise Exception("‚ùå Rate Limit persists. Aborting.")
    return full_transcript

# --- 3. Áü•ËÉΩÂàÜÊûê (Analysis - New SDK) ---

def analyze_text_with_gemini(transcript_text):
    print("üß† Gemini Analyzing (New SDK + Core Prompt)...", flush=True)
    
    # SZ„É°„ÇΩ„ÉÉ„Éâ„ÅÆË©≥Á¥∞„Éó„É≠„É≥„Éó„Éà (ÂÆåÂÖ®Á∂≠ÊåÅ)
    prompt = f"""
    „ÅÇ„Å™„Åü„ÅØ‰∏ñÁïåÊúÄÈ´òÂ≥∞„ÅÆ„Çπ„Éû„Éñ„É©ÔºàSuper Smash Bros.Ôºâ„Ç¢„Éä„É™„Çπ„Éà„Åß„ÅÇ„Çä„ÄÅË´ñÁêÜÁöÑ„Åã„Å§ÂÜ∑Âæπ„Å™„Ç≥„Éº„ÉÅ„É≥„Ç∞Ë®òÈå≤ÂÆò„Åß„Åô„ÄÇ
    Ê∏°„Åï„Çå„ÅüÂØæË©±„É≠„Ç∞„ÇíÁ≤æË™≠„Åó„ÄÅ‰ª•‰∏ã„ÅÆ3„Å§„ÅÆ„Çª„ÇØ„Ç∑„Éß„É≥„ÇíÂé≥ÂØÜ„Å™„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅßÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

    **„ÄêSection 1: „Éà„Éî„ÉÉ„ÇØÂà•„ÉªË©≥Á¥∞ÂàÜÊûê„É¨„Éù„Éº„Éà„Äë**
    ‰ºöË©±„ÅÆ‰∏≠„ÅßÊâ±„Çè„Çå„Åü„Äå‰∏ªË¶Å„Å™„Éà„Éî„ÉÉ„ÇØÔºà‰æãÔºöÂ¥ñ‰∏ä„Åå„ÇäÁã©„Çä„ÄÅ„É©„Ç§„É≥ÁÆ°ÁêÜ„ÄÅÂæ©Â∏∞ÈòªÊ≠¢Ôºâ„Äç„Çí„Åô„Åπ„Å¶ÊäΩÂá∫„Åó„ÄÅ
    **„Éà„Éî„ÉÉ„ÇØ„Åî„Å®„Å´**‰ª•‰∏ã„ÅÆ5Ë¶ÅÁ¥†„ÇíÂüã„ÇÅ„Å¶Ë®òËø∞„Åô„Çã„Åì„Å®„ÄÇ

    * **‚ë† ÁèæÁä∂ (Status):** „Éó„É¨„Ç§„É§„Éº„ÅåÁèæÂú®Ë°å„Å£„Å¶„ÅÑ„ÇãË°åÂãï„ÄÅÁôñ„ÄÅË™çË≠ò„Åó„Å¶„ÅÑ„ÇãÁä∂Ê≥Å„ÄÇ
    * **‚ë° Ë™≤È°å (Problem):** „Åù„ÅÆË°åÂãï„Å´„Çà„Å£„Å¶Áô∫Áîü„Åó„Å¶„ÅÑ„ÇãÂÖ∑‰ΩìÁöÑ„Å™„Éá„É°„É™„ÉÉ„Éà„ÄÇ
    * **‚ë¢ ÂéüÂõ† (Root Cause):** „Å™„Åú„Åù„ÅÆË™≤È°å„ÅåÁô∫Áîü„Åó„Å¶„ÅÑ„Çã„ÅÆ„ÅãÔºàÁü•Ë≠ò‰∏çË∂≥„ÄÅÊìç‰Ωú„Éü„Çπ„ÄÅÂà§Êñ≠„Éü„ÇπÁ≠âÔºâ„ÄÇ
    * **‚ë£ ÊîπÂñÑÊ°à (Solution):** ÂÖ∑‰ΩìÁöÑ„Å´„Å©„ÅÜË°åÂãï„ÇíÂ§â„Åà„Çã„Åπ„Åç„ÅãÔºàÊäÄ„ÅÆÂ§âÊõ¥„ÄÅ„Çø„Ç§„Éü„É≥„Ç∞„ÄÅÊÑèË≠òÈÖçÂàÜÔºâ„ÄÇ
    * **‚ë§ „ÇÑ„Çã„Åì„Å® (Next Action):** Ê¨°Âõû„ÅÆ„Éó„É¨„Ç§„ÅßÂç≥Â∫ß„Å´ÂÆüË°å„Åô„Åπ„Åç„ÄÅÂÖ∑‰ΩìÁöÑ„Ç¢„ÇØ„Ç∑„Éß„É≥Ôºà1Ë°åÔºâ„ÄÇ

    **„ÄêSection 2: ÊôÇÁ≥ªÂàó„É≠„Ç∞„Äë**
    „Çª„ÉÉ„Ç∑„Éß„É≥„ÅÆÊµÅ„Çå„ÇíÊôÇÁ≥ªÂàóÔºàTime-SeriesÔºâ„ÅßË©≥Á¥∞„Å´ÁÆáÊù°Êõ∏„Åç„Å´„Åô„Çã„Åì„Å®„ÄÇ

    **„ÄêSection 3: „É°„Çø„Éá„Éº„ÇøJSON„Äë**
    ‰ª•‰∏ã„ÅÆJSON„ÅÆ„Åø„ÇíÂá∫Âäõ„Åô„Çã„Åì„Å®„ÄÇ
    {{
      "student_name": "ÁîüÂæí„ÅÆÂêçÂâçÔºà‰∏çÊòé„Å™„ÇâUnknownÔºâ",
      "date": "YYYY-MM-DD",
      "next_action": "ÊúÄ„ÇÇÂÑ™ÂÖàÂ∫¶„ÅÆÈ´ò„ÅÑ„Ç¢„ÇØ„Ç∑„Éß„É≥1„Å§"
    }}

    ---
    **[DETAILED_REPORT_START]**
    („Åì„Åì„Å´Section 1„ÇíÂá∫Âäõ)
    **[DETAILED_REPORT_END]**

    **[RAW_LOG_START]**
    („Åì„Åì„Å´Section 2„ÇíÂá∫Âäõ)
    **[RAW_LOG_END]**

    **[JSON_START]**
    („Åì„Åì„Å´Section 3„ÇíÂá∫Âäõ)
    **[JSON_END]**
    ---

    „ÄêÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„Äë
    {transcript_text}
    """
    
    try:
        # ‚òÖ Êñ∞SDK„ÅÆÂëº„Å≥Âá∫„ÅóÊßãÊñá
        response = gemini_client.models.generate_content(
            model='gemini-1.5-flash',
            contents=prompt
        )
        text = response.text.strip()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini Analysis Failed: {e}")
        return {"student_name": "AnalysisError", "date": datetime.now().strftime('%Y-%m-%d')}, f"Analysis Error: {e}", transcript_text[:2000]
    
    def extract(s, e, src):
        m = re.search(f'{re.escape(s)}(.*?){re.escape(e)}', src, re.DOTALL)
        return m.group(1).strip() if m else ""

    report = extract("[DETAILED_REPORT_START]", "[DETAILED_REPORT_END]", text)
    time_log = extract("[RAW_LOG_START]", "[RAW_LOG_END]", text)
    json_str = extract("[JSON_START]", "[JSON_END]", text)
    
    try: data = json.loads(json_str)
    except: data = {"student_name": "Unknown", "date": datetime.now().strftime('%Y-%m-%d'), "next_action": "Check Logs"}
    return data, report, time_log

# --- 4. Ë≥áÁî£Âåñ ---

def notion_query_student(name):
    db_id = sanitize_id(FINAL_CONTROL_DB_ID)
    if not db_id: return None, name
    res = requests.post(f"https://api.notion.com/v1/databases/{db_id}/query", headers=HEADERS, json={"filter": {"property": "Name", "title": {"contains": name}}})
    d = res.json()
    if d.get("results"):
        row = d["results"][0]
        n = row["properties"]["Name"]["title"][0]["plain_text"]
        tid = row["properties"]["TargetID"]["rich_text"]
        return (sanitize_id(tid[0]["plain_text"]), n) if tid else (None, n)
    return None, name

def notion_create_page_heavy(db_id, props, children):
    res = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json={"parent": {"database_id": db_id}, "properties": props, "children": children[:100]})
    pid = res.json().get('id')
    if pid and len(children) > 100:
        for i in range(100, len(children), 100):
            requests.patch(f"https://api.notion.com/v1/blocks/{pid}/children", headers=HEADERS, json={"children": children[i:i+100]})

def cleanup_drive_file(file_id, rename_to):
    q = f"name='processed_coaching_logs' and '{INBOX_FOLDER_ID}' in parents"
    folders = drive_service.files().list(q=q).execute().get('files', [])
    fid = folders[0]['id'] if folders else drive_service.files().create(body={'name': 'processed_coaching_logs', 'mimeType': 'application/vnd.google-apps.folder', 'parents': [INBOX_FOLDER_ID]}, fields='id').execute().get('id')
    
    prev = ",".join(drive_service.files().get(fileId=file_id, fields='parents').execute().get('parents', []))
    drive_service.files().update(fileId=file_id, addParents=fid, removeParents=prev, body={'name': rename_to}).execute()
    print(f"‚úÖ Drive updated: {rename_to}")

# --- Main ---
def main():
    print("--- SZ AUTO LOGGER ULTIMATE (v84.0 - New SDK Migration) ---", flush=True)
    files = drive_service.files().list(q=f"'{INBOX_FOLDER_ID}' in parents and trashed=false and mimeType!='application/vnd.google-apps.folder'").execute().get('files', [])
    if not files: print("‚ÑπÔ∏è No files."); return

    for file in files:
        try:
            print(f"\nüìÇ Processing: {file['name']}")
            fpath = os.path.join(TEMP_DIR, file['name'])
            with open(fpath, "wb") as f:
                MediaIoBaseDownload(f, drive_service.files().get_media(fileId=file['id'])).next_chunk()
            
            srcs = []
            if file['name'].endswith('.zip'):
                with zipfile.ZipFile(fpath, 'r') as z:
                    z.extractall(TEMP_DIR)
                    for r, _, fs in os.walk(TEMP_DIR):
                        for af in fs:
                            if af.lower().endswith(('.flac', '.mp3', '.m4a', '.wav')) and 'final_mix' not in af and 'chunk' not in af:
                                srcs.append(os.path.join(r, af))
            else: srcs.append(fpath)
            
            if not srcs: continue
            
            mixed =
