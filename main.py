import os
import sys
import subprocess
import time
import json
import logging
import re
import zipfile
import shutil
from datetime import datetime

# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå¼·åˆ¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
try:
    import requests
    import google.generativeai as genai
    from pydub import AudioSegment
    from google.api_core.exceptions import ResourceExhausted 
except ImportError:
    print("ğŸ”„ Installing core libraries...", flush=True)
    subprocess.check_call([
        sys.executable, "-m", "pip", "install", "--upgrade", 
        "requests", "google-generativeai>=0.8.3", "pydub",
        "google-api-python-client", "google-auth"
    ])
    import requests
    import google.generativeai as genai
    from pydub import AudioSegment
    from google.api_core.exceptions import ResourceExhausted

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

# --- æœ€çµ‚è¨­å®šï¼ˆãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼‰ ---
# Control Center DBã®ID (é€šçŸ¥Botã§å®Ÿç¸¾ã®ã‚ã‚‹IDã‚’ä½¿ç”¨)
FINAL_CONTROL_DB_ID = "2b71bc8521e380868094ec506b41f664" 

# --- åˆæœŸåŒ– ---
TEMP_DIR = "downloads"
if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
os.makedirs(TEMP_DIR)

if os.getenv("GCP_SA_KEY"):
    with open("service_account.json", "w") as f:
        f.write(os.getenv("GCP_SA_KEY"))

def sanitize_id(raw_id):
    # å³å¯†ãªæ­£è¦è¡¨ç¾ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã—ã€ãƒã‚¤ãƒ•ãƒ³é™¤å»ã®ã¿ã«ç°¡ç´ åŒ–ã€‚
    if not raw_id: return "" # Noneã§ã¯ãªãç©ºæ–‡å­—åˆ—ã‚’è¿”ã™ã“ã¨ã§ã€ãƒ‘ã‚¹ã®NoneæŒ¿å…¥ã‚’é˜²ã
    return raw_id.replace("-", "").strip() # ãƒã‚¤ãƒ•ãƒ³ã¨å¤–éƒ¨ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»

try:
    NOTION_TOKEN = os.getenv("NOTION_TOKEN")
    HEADERS = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28" 
    }
    
    CONTROL_CENTER_ID = sanitize_id(FINAL_CONTROL_DB_ID)
    if not CONTROL_CENTER_ID:
        raise ValueError("CRITICAL: Final Control DB ID is empty after sanitization.")

    INBOX_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID")
    
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    SCOPES = ['https://www.googleapis.com/auth/drive']
    creds = service_account.Credentials.from_service_account_file("service_account.json", scopes=SCOPES)
    drive_service = build('drive', 'v3', credentials=creds)
    
except Exception as e:
    print(f"âŒ Setup Critical Error: {e}", flush=True)
    exit(1)

# --- Notion API é–¢æ•°ç¾¤ (Raw Requests) ---

def notion_query_database(db_id, query_filter):
    url = f"https://api.notion.com/v1/databases/{db_id}/query"
    try:
        res = requests.post(url, headers=HEADERS, json=query_filter)
        res.raise_for_status()
        return res.json()
    except requests.exceptions.HTTPError as e:
        print(f"âŒ Notion Query Error ({db_id}): Status {e.response.status_code}")
        print(f"   Detail: {e.response.text}")
        raise e

def notion_create_page(parent_db_id, properties, children):
    url = f"https://api.notion.com/v1/pages"
    payload = {
        "parent": {"database_id": parent_db_id},
        "properties": properties,
        "children": children
    }
    try:
        res = requests.post(url, headers=HEADERS, json=payload)
        res.raise_for_status()
        return res.json()
    except requests.exceptions.HTTPError as e:
        print(f"âŒ Notion Create Page Error: Status {e.response.status_code}")
        print(f"   Detail: {e.response.text}")
        raise e

# --- Google Drive File Management (Omitted for brevity, fully included in file) ---

def get_or_create_processed_folder():
    """Driveã®INBOXå†…ã« 'processed_coaching_logs' ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã—ã€ãªã‘ã‚Œã°ä½œæˆã™ã‚‹"""
    folder_name = "processed_coaching_logs"
    query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{INBOX_FOLDER_ID}' in parents and trashed=false"
    response = drive_service.files().list(q=query, fields='files(id)').execute()
    files = response.get('files', [])

    if files:
        return files[0]['id']
    else:
        file_metadata = {
            'name': folder_name,
            'mimeType': 'application/vnd.google-apps.folder',
            'parents': [INBOX_FOLDER_ID]
        }
        folder = drive_service.files().create(body=file_metadata, fields='id').execute()
        return folder.get('id')

def move_files_to_processed(file_ids, target_folder_id):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€ç¾åœ¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã¸ç§»å‹•ã™ã‚‹"""
    for file_id in file_ids:
        try:
            file = drive_service.files().get(fileId=file_id, fields='parents').execute()
            previous_parents = ",".join(file.get('parents'))
            
            drive_service.files().update(
                fileId=file_id,
                addParents=target_folder_id,
                removeParents=previous_parents,
                fields='id, parents'
            ).execute()
            print(f"â¡ï¸ Moved file {file_id} to processed folder successfully.", flush=True)
        except Exception as e:
            print(f"âŒ Failed to move file {file_id}. Error: {e}", flush=True)

# --- Audio/Drive/Gemini Helpers (Integration) ---

def download_file(file_id, file_name):
    request = drive_service.files().get_media(fileId=file_id)
    file_path = os.path.join(TEMP_DIR, file_name)
    with open(file_path, "wb") as fh:
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
    return file_path

def extract_audio_from_zip(zip_path):
    extracted_files = []
    extract_dir = os.path.join(TEMP_DIR, "extracted_" + os.path.basename(zip_path))
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    for root, dirs, files in os.walk(extract_dir):
        for file in files:
            if file.lower().endswith(('.flac', '.mp3', '.aac', '.wav', '.m4a')):
                extracted_files.append(os.path.join(root, file))
    return extracted_files

def mix_audio_files(file_paths):
    print(f"ğŸ›ï¸ Mixing {len(file_paths)} audio tracks...", flush=True)
    try:
        mixed = AudioSegment.from_file(file_paths[0])
        for path in file_paths[1:]:
            track = AudioSegment.from_file(path)
            mixed = mixed.overlay(track)
        output_path = os.path.join(TEMP_DIR, "mixed_session.mp3")
        mixed.export(output_path, format="mp3")
        return output_path
    except Exception as e:
        print(f"âš ï¸ Mixing Error: {e}. Using largest file instead.", flush=True)
        return max(file_paths, key=os.path.getsize)

def get_available_model_name():
    print("ğŸ” Searching for highest available Pro model...", flush=True)
    models = list(genai.list_models())
    available_names = [m.name for m in models if 'generateContent' in m.supported_generation_methods]

    for name in available_names:
        if 'gemini-2.5-pro' in name: return name 

    for name in available_names:
        if 'gemini-2.0-pro' in name: return name 
    
    for name in available_names:
        if 'gemini-2.5-flash' in name: return name
    for name in available_names:
        if 'gemini-2.0-flash' in name: return name
    
    return available_names[0] if available_names else 'models/gemini-2.0-flash'

def analyze_audio_auto(file_path):
    
    def generate_content_with_fallback(model_name, audio_file):
        """Quotaã‚¨ãƒ©ãƒ¼æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’Flashã«åˆ‡ã‚Šæ›¿ãˆã¦å†è©¦è¡Œã™ã‚‹"""
        
        current_model_name = model_name
        for attempt in range(2): # æœ€å¤§2å›è©¦è¡Œ (Pro -> Flash)
            try:
                print(f"ğŸ§  Analyzing with model: {current_model_name} (Attempt {attempt+1})", flush=True)
                model = genai.GenerativeModel(current_model_name)
                
                # Content Generation
                response = model.generate_content([prompt, audio_file])
                
                return response.text
                
            except ResourceExhausted as e:
                if attempt == 0 and ("pro" in current_model_name.lower()):
                    current_model_name = 'gemini-2.5-flash'
                    print("âš ï¸ Quota Exceeded for Pro. Falling back to Flash model.", flush=True)
                    time.sleep(5) 
                    continue
                else:
                    raise e
            
            except Exception as e:
                raise e

        # fallback loop end

    model_name_initial = get_available_model_name()
    audio_file = genai.upload_file(file_path)
    while audio_file.state.name == "PROCESSING":
        time.sleep(2)
        audio_file = genai.get_file(audio_file.name)
    if audio_file.state.name == "FAILED": raise ValueError("Audio Failed")
    
    # Final Prompt (v47.1/v50.0)
    prompt = """
    ã‚ãªãŸã¯**ãƒˆãƒƒãƒ—ãƒ»ã‚¹ãƒãƒ–ãƒ©ã‚¢ãƒŠãƒªã‚¹ãƒˆ**ã§ã‚ã‚Šã€å…·ä½“çš„ãªèª²é¡Œã‚’ç™ºè¦‹ã—è§£æ±ºã™ã‚‹ãŸã‚ã®**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ã§ã™ã€‚
    ã“ã®éŸ³å£°ã¯ã€**ã‚³ãƒ¼ãƒ (Hikari)** ã¨ **ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (ç”Ÿå¾’)** ã®å¯¾è©±ãƒ­ã‚°ã§ã™ã€‚

    ã€åˆ¶ç´„äº‹é …ã¨æ–‡è„ˆã®å„ªå…ˆåº¦ã€‘
    1. **æœ€å„ªå…ˆãƒ‰ãƒ¡ã‚¤ãƒ³ç”¨èª**: ã€Œç€åœ°ç‹©ã‚Šã€ã€Œå´–éš›ã€ã€Œå¾©å¸°é˜»æ­¢ã€ã€Œé–“åˆã„ã€ã€Œç¢ºå®šåæ’ƒã€ãªã©ã®å°‚é–€ç”¨èªã‚’å„ªå…ˆã—ã¦æ­£ç¢ºã«æŠ½å‡ºã›ã‚ˆã€‚
    2. **æ€è€ƒãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç™ºè¨€ã¨è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã€**èªçŸ¥ãƒã‚¤ã‚¢ã‚¹**ï¼ˆä¾‹ï¼šç¾çŠ¶ç¶­æŒãƒã‚¤ã‚¢ã‚¹ï¼‰ã¨ã‚²ãƒ¼ãƒ å†…è¡Œå‹•ã‚’ç´ã¥ã‘ã¦å ±å‘Šã›ã‚ˆã€‚

    ---
    **[RAW_TRANSCRIPTION_START]**
    ã¾ãšã€ä¼šè©±å…¨ä½“ã‚’å¯èƒ½ãªé™ã‚Šæ­£ç¢ºã«ã€é€èªè¨³å½¢å¼ã§æ–‡å­—èµ·ã“ã—ã›ã‚ˆã€‚
    **[RAW_TRANSCRIPTION_END]**
    ---

    ã€ã‚³ã‚¢åˆ†ææ§‹é€ ï¼š5è¦ç´ æŠ½å‡ºã€‘
    ä¸Šè¨˜ã®æ–‡å­—èµ·ã“ã—ã«åŸºã¥ãã€ã‚¹ãƒãƒ–ãƒ©ã®å†…å®¹ãŠã‚ˆã³å–ã‚Šçµ„ã¿æ”¹å–„ã«ãŠã‘ã‚‹è©±é¡Œã¯ã€ä»¥ä¸‹ã®5è¦ç´ ã«åˆ†å‰²ã—ã€è©³ç´°ãªè­°äº‹éŒ²ã¨ã—ã¦è¨˜éŒ²ã›ã‚ˆã€‚
    * **ç¾çŠ¶** (Current Status)
    * **èª²é¡Œ** (Problem/Issue)
    * **åŸå› ** (Root Cause)
    * **æ”¹å–„æ¡ˆ** (Proposed Solution)
    * **ã‚„ã‚‹ã“ã¨** (Next Action/Commitment)

    ã€æœ€çµ‚å‡ºåŠ›å½¢å¼ã€‘
    ä¸Šè¨˜ã®è©³ç´°åˆ†æã«åŸºã¥ãã€æœ€çµ‚çš„ãªã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒ³ãƒˆã®è¨˜éŒ²ã¨ã—ã¦ã€ä»¥ä¸‹ã®JSONæ§‹é€ ã®ã¿ã‚’ç”Ÿæˆã›ã‚ˆã€‚
    
    {
      "student_name": "ç”Ÿå¾’ã®åå‰ï¼ˆä¾‹: ã‚‰ãã´, ãƒˆãƒ­ãƒ”ã‚¦ã‚¹ï¼‰",
      "date": "YYYY-MM-DD (ä¸æ˜ãªã‚‰Today)",
      "summary": "[æ„Ÿæƒ…ã‚¢ã‚¤ã‚³ãƒ³] - ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ç‰¹å®šã•ã‚ŒãŸã‚³ã‚¢ãªèª²é¡Œã¨ã€ãã‚Œã‚’è¶…ãˆã‚‹ãŸã‚ã®æ–°ã—ã„**ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒ³ãƒˆ**ï¼ˆ150å­—ä»¥å†…ï¼‰ã€‚",
      "next_action": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒå…·ä½“çš„ã«ã‚³ãƒŸãƒƒãƒˆã—ãŸã€æ¬¡ã®ã‚¿ã‚¹ã‚¯ã¨**æœŸé™ï¼ˆYYYY-MM-DDã¾ãŸã¯Næ—¥å¾Œï¼‰**"
    }
    """
    
    response_text = generate_content_with_fallback(model_name_initial, audio_file)
    
    # 4. Cleanup and Parsing
    try: genai.delete_file(audio_file.name)
    except: pass

    text = response_text.strip()
    
    transcript_match = re.search(r'\[RAW_TRANSCRIPTION_START\](.*?)\[RAW_TRANSCRIPTION_END\]', text, re.DOTALL)
    raw_transcript = transcript_match.group(1).strip() if transcript_match else "ERROR: Raw transcript not found."
    
    json_match = re.search(r'\{.*\}', text, re.DOTALL)
    if json_match: 
        data = json.loads(json_match.group(0))
        
        if data.get('date') in ['Unknown', 'Today']:
            data['date'] = datetime.now().strftime('%Y-%m-%d')
        return data, raw_transcript 
    else: 
        raise ValueError("JSON Parse Failed")

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    print("--- VERSION: AI OUTPUT LOGGING (v54.0) ---", flush=True)
    
    if not os.getenv("DRIVE_FOLDER_ID"):
        print("âŒ Error: DRIVE_FOLDER_ID is missing!", flush=True)
        return

    # 1. Drive Search (Find unprocessed files)
    try:
        results = drive_service.files().list(
            q=f"'{INBOX_FOLDER_ID}' in parents and mimeType != 'application/vnd.google-apps.folder' and trashed = false",
            fields="files(id, name, createdTime)",
            orderBy="createdTime desc"
        ).execute()
    except Exception as e:
        print(f"âŒ Drive Search Error: {e}", flush=True)
        return
    
    files = results.get('files', [])
    
    if not files:
        print("â„¹ï¸ No new files found. Exiting.", flush=True)
        return

    # 2. Manual Input Check
    manual_name = os.getenv("MANUAL_STUDENT_NAME")

    # 3. Main Processing Loop
    for file in files:
        file_id = file['id']
        file_name = file['name']
        
        try:
            print(f"\nProcessing File: {file_name}", flush=True)
            
            # 3.1. Audio Processing
            local_audio_paths = []
            path = download_file(file_id, file_name)
            if file_name.lower().endswith('.zip'):
                local_audio_paths.extend(extract_audio_from_zip(path))
            else:
                local_audio_paths.append(path)
            
            if not local_audio_paths:
                raise ValueError("No valid audio tracks found after extraction.")
            
            mixed_path = mix_audio_files(local_audio_paths)
            
            # 3.2. --- â˜…è§£æå®Ÿè¡Œï¼šJSONãƒ‡ãƒ¼ã‚¿ã¨Raw Transcriptã®ä¸¡æ–¹ã‚’å–å¾—â˜… ---
            full_analysis, raw_transcript = analyze_audio_auto(mixed_path)
            
            # --- â˜…æ–°è¦æ©Ÿèƒ½ï¼šAIå‡ºåŠ›çµæœã®å®Ÿè¡Œãƒ­ã‚°è¨˜éŒ²â˜… ---
            print("\n--- AI ANALYSIS OUTPUT (START) ---", flush=True)
            print(f"Student: {full_analysis.get('student_name', 'N/A')}", flush=True)
            print(f"Summary: {full_analysis.get('summary', 'N/A')}", flush=True)
            print(f"Next Action: {full_analysis.get('next_action', 'N/A')}", flush=True)
            print("\n[RAW TRANSCRIPT]", flush=True)
            print(raw_transcript, flush=True)
            print("--- AI ANALYSIS OUTPUT (END) ---\n", flush=True)
            # --- è¨˜éŒ²çµ‚äº† ---

            # 3.3. Name Logic
            final_student_name = manual_name if manual_name else full_analysis['student_name']
            print(f"â„¹ï¸ Target Student for Lookup: '{final_student_name}'", flush=True)

            # --- 4. Notion Search and Write ---
            search_filter = {
                "filter": {
                    "property": "Name",
                    "title": { "contains": final_student_name } 
                }
            }
            
            cc_res_data = notion_query_database(CONTROL_CENTER_ID, search_filter)
            results_list = cc_res_data.get("results", [])
            
            if not results_list:
                print(f"âŒ Error: Student '{final_student_name}' not found in Control Center. Skipping write.", flush=True)
                continue 

            # 5. Extract Target ID and Write
            target_id_prop = results_list[0]["properties"].get("TargetID", {}).get("rich_text", [])
            
            if not target_id_prop:
                print("âŒ Error: TargetID is empty in Control Center. Skipping write.", flush=True)
                continue
            
            final_target_id = sanitize_id(target_id_prop[0]["plain_text"])

            if not final_target_id:
                print(f"âŒ Error: TargetID for {final_student_name} is invalid.", flush=True)
                continue

            # 5.1. --- â˜…ãƒ¡ã‚¤ãƒ³ãƒ­ã‚°ï¼ˆè¦ç´„ï¼‰ã®ä½œæˆã¨æ›¸ãè¾¼ã¿â˜… ---
            properties_summary = {
                "åå‰": {"title": [{"text": {"content": f"{full_analysis['date']} ãƒ­ã‚° (è¦ç´„)"}}]},
                "æ—¥ä»˜": {"date": {"start": full_analysis['date']}}
            }
            children_summary = [
                {"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"text": {"content": full_analysis['summary']}}]}},
                {"object": "block", "type": "heading_3", "heading_3": {"rich_text": [{"text": {"content": "Next Action"}}]}},
                {"object": "block", "type": "paragraph", "paragraph": {"rich_text": [{"text": {"content": full_analysis.get('next_action', 'ãªã—')}}]}}
            ]
            notion_create_page(final_target_id, properties_summary, children_summary)
            print(f"âœ… Summary Log written for {final_student_name}.", flush=True)

            
            # 5.2. --- â˜…æ–°è¦æ©Ÿèƒ½ï¼šç´”ç²‹ãªæ–‡å­—èµ·ã“ã—ãƒ­ã‚°ã®ä½œæˆã¨æ›¸ãè¾¼ã¿â˜… ---
            properties_transcript = {
                "åå‰": {"title": [{"text": {"content": f"{full_analysis['date']} ãƒ­ã‚° (å…¨æ–‡)"}}]},
                "æ—¥ä»˜": {"date": {"start": full_analysis['date']}}
            }
            
            children_transcript = []
            if raw_transcript and raw_transcript != "ERROR: Raw transcript not found.":
                # 1è¡Œãšã¤ãƒ–ãƒ­ãƒƒã‚¯ã«å¤‰æ›
                for line in raw_transcript.split('\n'):
                    if line.strip(): 
                        children_transcript.append({
                            "object": "block",
                            "type": "paragraph",
                            "paragraph": {"rich_text": [{"text": {"content": line}}]}
                        })
            
            if children_transcript:
                notion_create_page(final_target_id, properties_transcript, children_transcript)
                print(f"âœ… Full Transcript written for {final_student_name}.", flush=True)
            else:
                print("âš ï¸ Transcript was empty or not found. Skipping full text write.", flush=True)
                
            
            # 6. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            processed_folder_id = get_or_create_processed_folder()
            move_files_to_processed([file_id], processed_folder_id)
            print(f"ğŸ‰ PROJECT SUCCESS: Completed processing for {final_student_name}.", flush=True)
            
       except Exception as e:
             print(f"âŒ UNHANDLED CRASH IN LOOP: {e}", flush=True)
             import traceback
             traceback.print_exc()
        finally:
            if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
            os.makedirs(TEMP_DIR) 

if __name__ == "__main__":
    main()
