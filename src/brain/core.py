import os
import re
import dspy
import sqlite3
import google.generativeai as genai
from pinecone import Pinecone

# --- Config ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

# DB Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FRAME_DB_PATH = os.path.join(BASE_DIR, '../../data/framedata.db')

# --- 1. Dynamic Model Resolver ---
def get_best_models():
    """
    Google APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªå…¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€
    'Thinking'(è³¢ã•å„ªå…ˆ) ã¨ 'Reflex'(é€Ÿåº¦å„ªå…ˆ) ã®ãã‚Œãã‚Œã§æœ€å¼·ã®ãƒ¢ãƒ‡ãƒ«IDã‚’è¿”ã™ã€‚
    """
    genai.configure(api_key=GEMINI_API_KEY)
    
    try:
        all_models = list(genai.list_models())
        candidates = []
        for m in all_models:
            name = m.name.replace("models/", "")
            if "gemini" in name and "vision" not in name and "embedding" not in name:
                candidates.append(name)
        
        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•° (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ > ã‚°ãƒ¬ãƒ¼ãƒ‰ > æœ€æ–°æ€§)
        def calculate_score(name, is_speed_priority=False):
            score = 0
            # Version (2.5 -> 2500, 2.0 -> 2000, 1.5 -> 1500)
            version_match = re.search(r"(\d+\.\d+)", name)
            if version_match:
                score += float(version_match.group(1)) * 1000
            
            # Grade
            if "ultra" in name: score += 300
            elif "pro" in name: score += 200
            elif "flash" in name: 
                # é€Ÿåº¦å„ªå…ˆãªã‚‰Flashã‚’é«˜è©•ä¾¡ã€æ€è€ƒå„ªå…ˆãªã‚‰ä½è©•ä¾¡
                score += 500 if is_speed_priority else 100
            
            # Latest / Experimental
            if "exp" in name: score += 50
            if "thinking" in name and not is_speed_priority: score += 20 # æ€è€ƒãƒ¢ãƒ‡ãƒ«ãªã‚‰ThinkingåŠ ç‚¹
            
            return score

        # Thinking Model (è³¢ã•é‡è¦–: Pro/Ultra/Thinking)
        thinking_candidates = sorted(candidates, key=lambda x: calculate_score(x, is_speed_priority=False), reverse=True)
        best_thinking = thinking_candidates[0] if thinking_candidates else "gemini-1.5-pro"

        # Reflex Model (é€Ÿåº¦é‡è¦–: Flashç³»ã®ä¸­ã§æœ€å¼·ã®ã‚‚ã®)
        reflex_candidates = sorted(candidates, key=lambda x: calculate_score(x, is_speed_priority=True), reverse=True)
        best_reflex = reflex_candidates[0] if reflex_candidates else "gemini-1.5-flash"

        print(f"ğŸ§  Dynamic Model Selection:\n  Thinking Engine: {best_thinking}\n  Reflex Engine:   {best_reflex}")
        return best_thinking, best_reflex

    except Exception as e:
        print(f"âš ï¸ Model resolution failed: {e}. Falling back to defaults.")
        return "gemini-1.5-pro", "gemini-1.5-flash"

# ãƒ¢ãƒ‡ãƒ«è§£æ±ºã¨DSPyè¨­å®š
THINKING_MODEL_ID, REFLEX_MODEL_ID = get_best_models()

# DSPyã®è¨­å®š
# æ³¨æ„: dspy.Google ã¯ 'models/' æ¥é ­è¾ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹ãŸã‚è£œå®Œ
reflex_lm = dspy.Google(model=f"models/{REFLEX_MODEL_ID.replace('models/', '')}", api_key=GEMINI_API_KEY)
thinking_lm = dspy.Google(model=f"models/{THINKING_MODEL_ID.replace('models/', '')}", api_key=GEMINI_API_KEY)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ€è€ƒãƒ¢ãƒ‡ãƒ«
dspy.settings.configure(lm=thinking_lm)

# --- 2. Define Signatures ---
class IntentClassifier(dspy.Signature):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€æœ€é©ãªæƒ…å ±ã‚½ãƒ¼ã‚¹ã‚’æ±ºå®šã›ã‚ˆã€‚
    - å…·ä½“çš„ãªæŠ€ã®æ•°å€¤(ç™ºç”Ÿã€ç¡¬ç›´å·®ã€ãƒ€ãƒ¡ãƒ¼ã‚¸ç­‰) â†’ 'frame_data'
    - ç«‹ã¡å›ã‚Šã€å¯¾ç­–ã€å¿ƒç†æˆ¦ã€è€ƒãˆæ–¹ã€ã‚³ãƒ³ãƒœãªã© â†’ 'theory'
    """
    question = dspy.InputField(desc="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    intent = dspy.OutputField(desc="'frame_data' or 'theory'")
    character = dspy.OutputField(desc="é–¢é€£ã‚­ãƒ£ãƒ©å (ä¾‹: ã‚¯ãƒ©ã‚¦ãƒ‰, ãƒã‚¹)ã€‚ä¸æ˜ãªã‚‰None")
    move = dspy.OutputField(desc="é–¢é€£ã™ã‚‹æŠ€å (ä¾‹: ç©ºå‰, ä¸ŠB)ã€‚ä¸æ˜ãªã‚‰None")

class CoachAnswer(dspy.Signature):
    """
    ã‚ãªãŸã¯ä¸–ç•Œä¸€ã®ã‚¹ãƒãƒ–ãƒ©ã‚³ãƒ¼ãƒã§ã™ã€‚Contextã«åŸºã¥ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å‹åˆ©ã¸å°ãå›ç­”ã‚’ä½œæˆã›ã‚ˆã€‚
    """
    context = dspy.InputField(desc="æ¤œç´¢ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚„æ”»ç•¥ç†è«–")
    question = dspy.InputField(desc="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    answer = dspy.OutputField(desc="è«–ç†çš„ã‹ã¤å…·ä½“çš„ãªã‚³ãƒ¼ãƒãƒ³ã‚°å›ç­”")

# --- 3. Retrievers ---
def search_frame_data(char_name, move_name):
    """SQLiteã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢"""
    if not os.path.exists(FRAME_DB_PATH): return "DB Error"
    conn = sqlite3.connect(FRAME_DB_PATH)
    c = conn.cursor()
    query = """
        SELECT m.move_name, m.startup, m.total_frames, m.landing_lag, m.shield_advantage, m.base_damage, m.note 
        FROM moves m JOIN characters c ON m.char_id = c.id 
        WHERE c.name LIKE ? AND m.move_name LIKE ?
    """
    c.execute(query, (f'%{char_name}%', f'%{move_name}%'))
    rows = c.fetchall()
    conn.close()
    
    if not rows: return "è©²å½“ãƒ‡ãƒ¼ã‚¿ãªã—"
    
    res = f"ã€{char_name}ã®{move_name} ãƒ‡ãƒ¼ã‚¿ã€‘\n"
    for r in rows:
        res += f"- {r[0]}: ç™ºç”Ÿ{r[1]}F / å…¨ä½“{r[2]}F / ã‚¬ãƒ¼ãƒ‰ç¡¬ç›´å·®{r[4]}F / ãƒ€ãƒ¡ãƒ¼ã‚¸{r[5]}%\n"
    return res

def search_theory(query):
    """Pineconeã‹ã‚‰ç†è«–ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
    if not PINECONE_API_KEY: return "Pinecone Key Missing"
    try:
        pc = Pinecone(api_key=PINECONE_API_KEY)
        index = pc.Index("smash-coach-index")
        
        # Embeddingã‚‚å‹•çš„ã«æœ€å¼·ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ãŸã„ãŒã€
        # Ingestæ™‚ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«(text-embedding-004)ã‚’ä½¿ã‚ãªã„ã¨ç©ºé–“ãŒã‚ºãƒ¬ã¦ãƒ’ãƒƒãƒˆã—ãªããªã‚‹ãŸã‚å›ºå®š
        genai.configure(api_key=GEMINI_API_KEY)
        emb = genai.embed_content(model="models/text-embedding-004", content=query)
        
        results = index.query(vector=emb['embedding'], top_k=5, include_metadata=True)
        
        context = "ã€å‚ç…§ã•ã‚ŒãŸæ”»ç•¥ç†è«–ã€‘\n"
        if not results['matches']:
            return "é–¢é€£ã™ã‚‹ç†è«–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
        for m in results['matches']:
            meta = m['metadata']
            score = m['score']
            if score < 0.5: continue
            context += f"--- {meta.get('title')} (é–¢é€£åº¦:{score:.2f}) ---\n{meta.get('text_content')}\n\n"
            
        return context
    except Exception as e:
        return f"Search Error: {e}"

# --- 4. Brain Module ---
class SmashBrain(dspy.Module):
    """
    === DSPy Reasoning Engine (Legacy Type A) ===
    
    STUDENT COMPONENT: Reasoning orchestrator combining Intent Classification + Context Retrieval + Answer Generation
    
    This is the legacy Type A architecture (before Type B refactoring in model.py).
    Maintained for backward compatibility. New code should use SmashCoach (Type B).
    
    === Pipeline ===
    1. IntentClassifier (Reflex LM): Determine info source (frame_data vs theory)
    2. Search Dispatch: Query SQLite (frame_data) or Pinecone (theory)
    3. CoachAnswer (Thinking LM): Generate response using ChainOfThought reasoning
    
    === Optimization Paths ===
    - dspy.Teleprompter: Auto-tune IntentClassifier and CoachAnswer prompts
    - dspy.BootstrapFewShot: Learn from user /teach corrections
    - Dual-Model Strategy: Reflex for classification (fast), Thinking for generation (quality)
    """
    def __init__(self):
        super().__init__()
        self.classify = dspy.ChainOfThought(IntentClassifier)
        self.generate = dspy.ChainOfThought(CoachAnswer)
    
    def forward(self, question):
        """
        === DSPy Forward Pass ===
        
        Orchestrates two-stage reasoning:
        1. Intent Classification: Determines whether to use frame_data or theory
        2. Context-Aware Generation: Generates coaching response based on classified intent
        
        Args:
            question: User's coaching query (str)
        
        Returns:
            response.answer: Coaching advice as string
        
        === Implementation Details ===
        - Uses asyncio.to_thread() compatibility (blocking I/O safe in Discord context)
        - Dynamic model selection: Reflex for fast classification, Thinking for quality generation
        - Fallback: If search fails, still attempts to generate response from question context
        
        === Redefinability ===
        - LM models: Can be swapped via dspy.context(lm=...)
        - Retrieval sources: Can be extended to support additional databases
        - Signatures: IntentClassifier and CoachAnswer prompts are dspy.Signature (tunable)
        """
        # 1. æ„å›³åˆ†é¡ (Reflex Model: æœ€å¼·ã®Flashã‚’ä½¿ç”¨)
        with dspy.context(lm=reflex_lm):
            classification = self.classify(question=question)
        
        intent = classification.intent.lower()
        char = classification.character
        move = classification.move
        
        # 2. æƒ…å ±æ¤œç´¢
        context = ""
        if "frame" in intent or "data" in intent:
            if char:
                context = search_frame_data(char, move if move else "")
            else:
                context = search_theory(question)
        else:
            context = search_theory(question)
            
        # 3. å›ç­”ç”Ÿæˆ (Thinking Model: æœ€å¼·ã®Pro/Expã‚’ä½¿ç”¨)
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒThinkingãªã®ã§ãã®ã¾ã¾å®Ÿè¡Œ
        response = self.generate(context=context, question=question)
        
        return response.answer
