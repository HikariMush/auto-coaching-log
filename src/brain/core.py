import os
import re
import dspy
import sqlite3
import google.generativeai as genai
from pinecone import Pinecone

# --- Config ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

# DB Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FRAME_DB_PATH = os.path.join(BASE_DIR, '../../data/framedata.db')

# --- 1. Dynamic Model Resolver ---
def get_best_models():
    """
    Google APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªå…¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€
    'Thinking'(è³¢ã•å„ªå…ˆ) ã¨ 'Reflex'(é€Ÿåº¦å„ªå…ˆ) ã®ãã‚Œãã‚Œã§æœ€å¼·ã®ãƒ¢ãƒ‡ãƒ«IDã‚’è¿”ã™ã€‚
    """
    genai.configure(api_key=GEMINI_API_KEY)
    
    try:
        all_models = list(genai.list_models())
        candidates = []
        for m in all_models:
            name = m.name.replace("models/", "")
            if "gemini" in name and "vision" not in name and "embedding" not in name:
                candidates.append(name)
        
        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•° (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ > ã‚°ãƒ¬ãƒ¼ãƒ‰ > æœ€æ–°æ€§)
        def calculate_score(name, is_speed_priority=False):
            score = 0
            # Version (2.5 -> 2500, 2.0 -> 2000, 1.5 -> 1500)
            version_match = re.search(r"(\d+\.\d+)", name)
            if version_match:
                score += float(version_match.group(1)) * 1000
            
            # Grade
            if "ultra" in name: score += 300
            elif "pro" in name: score += 200
            elif "flash" in name: 
                # é€Ÿåº¦å„ªå…ˆãªã‚‰Flashã‚’é«˜è©•ä¾¡ã€æ€è€ƒå„ªå…ˆãªã‚‰ä½è©•ä¾¡
                score += 500 if is_speed_priority else 100
            
            # Latest / Experimental
            if "exp" in name: score += 50
            if "thinking" in name and not is_speed_priority: score += 20 # æ€è€ƒãƒ¢ãƒ‡ãƒ«ãªã‚‰ThinkingåŠ ç‚¹
            
            return score

        # Thinking Model (è³¢ã•é‡è¦–: Pro/Ultra/Thinking)
        thinking_candidates = sorted(candidates, key=lambda x: calculate_score(x, is_speed_priority=False), reverse=True)
        best_thinking = thinking_candidates[0] if thinking_candidates else "gemini-1.5-pro"

        # Reflex Model (é€Ÿåº¦é‡è¦–: Flashç³»ã®ä¸­ã§æœ€å¼·ã®ã‚‚ã®)
        reflex_candidates = sorted(candidates, key=lambda x: calculate_score(x, is_speed_priority=True), reverse=True)
        best_reflex = reflex_candidates[0] if reflex_candidates else "gemini-1.5-flash"

        print(f"ğŸ§  Dynamic Model Selection:\n  Thinking Engine: {best_thinking}\n  Reflex Engine:   {best_reflex}")
        return best_thinking, best_reflex

    except Exception as e:
        print(f"âš ï¸ Model resolution failed: {e}. Falling back to defaults.")
        return "gemini-1.5-pro", "gemini-1.5-flash"

# ãƒ¢ãƒ‡ãƒ«è§£æ±ºã¨DSPyè¨­å®š
THINKING_MODEL_ID, REFLEX_MODEL_ID = get_best_models()

# DSPyã®è¨­å®š
# æ³¨æ„: dspy.LM ã¯ LiteLLMå½¢å¼ 'gemini/model-name' ã‚’ä½¿ç”¨
reflex_lm = dspy.LM(model=f"gemini/{REFLEX_MODEL_ID.replace('models/', '')}", api_key=GEMINI_API_KEY)
thinking_lm = dspy.LM(model=f"gemini/{THINKING_MODEL_ID.replace('models/', '')}", api_key=GEMINI_API_KEY)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ€è€ƒãƒ¢ãƒ‡ãƒ«
dspy.settings.configure(lm=thinking_lm)

# --- 2. Define Signatures ---
class IntentClassifier(dspy.Signature):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€æœ€é©ãªæƒ…å ±ã‚½ãƒ¼ã‚¹ã‚’æ±ºå®šã›ã‚ˆã€‚
    - å…·ä½“çš„ãªæŠ€ã®æ•°å€¤(ç™ºç”Ÿã€ç¡¬ç›´å·®ã€ãƒ€ãƒ¡ãƒ¼ã‚¸ç­‰) â†’ 'frame_data'
    - ç«‹ã¡å›ã‚Šã€å¯¾ç­–ã€å¿ƒç†æˆ¦ã€è€ƒãˆæ–¹ã€ã‚³ãƒ³ãƒœãªã© â†’ 'theory'
    """
    question = dspy.InputField(desc="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    intent = dspy.OutputField(desc="'frame_data' or 'theory'")
    character = dspy.OutputField(desc="é–¢é€£ã‚­ãƒ£ãƒ©å (ä¾‹: ã‚¯ãƒ©ã‚¦ãƒ‰, ãƒã‚¹)ã€‚ä¸æ˜ãªã‚‰None")
    move = dspy.OutputField(desc="é–¢é€£ã™ã‚‹æŠ€å (ä¾‹: ç©ºå‰, ä¸ŠB)ã€‚ä¸æ˜ãªã‚‰None")

class ConversationSummarizer(dspy.Signature):
    """
    éå»ã®ä¼šè©±ã‚’è¦ç´„ã—ã€ç¾åœ¨ã®è³ªå•ã«é–¢é€£ã™ã‚‹é‡è¦ãªæƒ…å ±ã ã‘ã‚’æŠ½å‡ºã€‚
    
    ç›®çš„: ãƒˆãƒ¼ã‚¯ãƒ³æ•°å‰Šæ¸› + æ–‡è„ˆç†è§£ã®å‘ä¸Š
    
    ä¾‹:
    ä¼šè©±å±¥æ­´: "User: ãƒãƒªã‚ªã®ç©ºå‰ã¯ï¼Ÿ\nBot: ç™ºç”Ÿ3Fã€å…¨ä½“29F...\nUser: ã‚¬ãƒ¼ãƒ‰ã•ã‚ŒãŸæ™‚ã¯ï¼Ÿ\nBot: -9Fãªã®ã§æ´ã¿ãŒç¢ºå®š..."
    ç¾åœ¨ã®è³ªå•: "ä»–ã«ã©ã‚“ãªæŠ€ãŒç¢ºå®šã™ã‚‹ï¼Ÿ"
    æŠ½å‡ºçµæœ: "ãƒãƒªã‚ªã®ç©ºå‰ã‚’ã‚¬ãƒ¼ãƒ‰ã™ã‚‹ã¨-9Fæœ‰åˆ©ã€‚æ´ã¿ä»¥å¤–ã®ç¢ºå®šåæ’ƒã‚’è³ªå•ã—ã¦ã„ã‚‹ã€‚"
    """
    conversation_history = dspy.InputField(desc="éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆUser/Botå½¢å¼ï¼‰")
    current_question = dspy.InputField(desc="ç¾åœ¨ã®è³ªå•")
    relevant_context = dspy.OutputField(desc="ç¾åœ¨ã®è³ªå•ã«é–¢é€£ã™ã‚‹éå»ã®æ–‡è„ˆã®ã¿ï¼ˆç°¡æ½”ã«è¦ç´„ï¼‰")

class QueryExpansion(dspy.Signature):
    """
    è³ªå•ã‚’è¤‡æ•°ã®è¦³ç‚¹ã«åˆ†è§£ã—ã¦ã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªæ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚
    
    ä¾‹:
    è³ªå•: ã€Œãƒãƒªã‚ªã®å¾©å¸°é˜»æ­¢ã¯ï¼Ÿã€
    æ‹¡å¼µ: ["ãƒãƒªã‚ªã®å¾©å¸°ãƒ«ãƒ¼ãƒˆ", "å´–å¤–ã§ã®ç«‹ã¡å›ã‚Š", "å¾©å¸°æŠ€ã®å¯¾ç­–", "ãƒªã‚¹ã‚¯ãƒªã‚¿ãƒ¼ãƒ³è©•ä¾¡"]
    
    DSPyæœ€é©åŒ–å¯¾è±¡: ã“ã®Signatureã‚‚Teleprompterã§æœ€é©åŒ–å¯èƒ½
    """
    question = dspy.InputField(desc="å…ƒã®è³ªå•")
    expanded_queries = dspy.OutputField(desc="3-5å€‹ã®ã‚µãƒ–ã‚¯ã‚¨ãƒªï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ã€‚è³ªå•ã‚’ç•°ãªã‚‹è¦³ç‚¹ã‹ã‚‰æ‰ãˆãŸæ¤œç´¢ã‚¯ã‚¨ãƒªã€‚")

class RelevanceScorer(dspy.Signature):
    """
    æ¤œç´¢çµæœã®é–¢é€£æ€§ã‚’1-10ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã€‚
    
    ç›®çš„: ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã ã‘ã§ã¯åˆ¤æ–­ã§ããªã„ã€ŒçœŸã®é–¢é€£æ€§ã€ã‚’è©•ä¾¡
    
    è©•ä¾¡åŸºæº–:
    - è³ªå•ã«ç›´æ¥ç­”ãˆã‚‹å†…å®¹ã‹ï¼Ÿ
    - è³ªå•ã®æ–‡è„ˆã«åˆã£ã¦ã„ã‚‹ã‹ï¼Ÿ
    - å®Ÿç”¨çš„ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
    """
    question = dspy.InputField(desc="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    document_title = dspy.InputField(desc="æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«")
    document_content = dspy.InputField(desc="æ–‡æ›¸ã®å†…å®¹ï¼ˆå…ˆé ­500æ–‡å­—ï¼‰")
    relevance_score = dspy.OutputField(desc="é–¢é€£æ€§ã‚¹ã‚³ã‚¢ï¼ˆ1-10ï¼‰ã€‚10=å®Œå…¨ã«é–¢é€£ã€1=ã»ã¼ç„¡é–¢ä¿‚")

class FrameDataAnswer(dspy.Signature):
    """
    ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚
    
    **çµ¶å¯¾å³å®ˆäº‹é …**ï¼š
    1. frame_dataã«è¨˜è¼‰ã•ã‚ŒãŸæ•°å€¤ã‚’**ä¸€åˆ‡æ”¹å¤‰ã—ã¦ã¯ãªã‚‰ãªã„**
    2. æ•°å€¤ãŒä¸æ˜ãªå ´åˆã¯ã€Œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨æ­£ç›´ã«å›ç­”ã™ã‚‹
    3. æ¨æ¸¬ã‚„æ¦‚ç®—ã¯**çµ¶å¯¾ã«ç¦æ­¢**
    4. frame_dataã«è¨˜è¼‰ã•ã‚ŒãŸæ•°å€¤ã‚’ãã®ã¾ã¾ä½¿ç”¨ã™ã‚‹ã“ã¨
    
    ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¼ã‚¿ã®æé€ ï¼‰ã¯å³ç¦ã§ã™ã€‚
    æä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ã€å­˜åœ¨ã—ãªã„æƒ…å ±ã‚’å‰µä½œã—ãªã„ã§ãã ã•ã„ã€‚
    """
    frame_data = dspy.InputField(desc="SQLiteã‹ã‚‰å–å¾—ã—ãŸæ­£ç¢ºãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã€‚ã“ã®æ•°å€¤ã‚’çµ¶å¯¾ã«æ”¹å¤‰ã—ãªã„ã“ã¨ã€‚")
    question = dspy.InputField(desc="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    answer = dspy.OutputField(desc="frame_dataã®æ•°å€¤ã‚’ãã®ã¾ã¾ä½¿ã£ãŸæ­£ç¢ºãªå›ç­”ã€‚æ•°å€¤ã®æ”¹å¤‰ãƒ»æ¨æ¸¬ãƒ»æ¦‚ç®—ã¯çµ¶å¯¾ç¦æ­¢ã€‚")

class CoachAnswer(dspy.Signature):
    """
    ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚¹ãƒãƒ–ãƒ©ã‚³ãƒ¼ãƒã§ã™ã€‚Contextã¨ä¼šè©±å±¥æ­´ã«åŸºã¥ãã€å†·é™ã‹ã¤å®¢è¦³çš„ãªåˆ†æã¨å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
    éåº¦ã«ç†±è¡€çš„ãªè¡¨ç¾ã¯é¿ã‘ã€äº‹å®Ÿã¨è«–ç†ã‚’é‡è¦–ã—ãŸè½ã¡ç€ã„ãŸãƒˆãƒ¼ãƒ³ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
    
    **é‡è¦**: å›ç­”ã¯ä»¥ä¸‹ã®æ§‹é€ åŒ–å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
    
    [1] ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ»åŸºç¤æƒ…å ±
    ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰ç™ºç”ŸFã€å…¨ä½“Fã€ãƒ€ãƒ¡ãƒ¼ã‚¸%ãªã©ã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿
    
    [2] æŠ€è¡“çš„è§£èª¬
    ç¡¬ç›´å·®ã®è¨ˆç®—ã€ç¢ºå®šåæ’ƒã€ã‚³ãƒ³ãƒœãƒ«ãƒ¼ãƒˆãªã©ã®æŠ€è¡“çš„è©³ç´°
    
    [3] å®Ÿæˆ¦ã§ã®ä½¿ã„æ–¹
    ç«‹ã¡å›ã‚Šã§ã®ä½¿ç”¨å ´é¢ã€ãƒªã‚¹ã‚¯ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã€çŠ¶æ³åˆ¥ã®é¸æŠè‚¢
    
    [4] è£œè¶³ãƒ»æ³¨æ„ç‚¹
    ã‚­ãƒ£ãƒ©å·®ã€åˆå¿ƒè€…å‘ã‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€ã‚ˆãã‚ã‚‹é–“é•ã„ãªã©
    
    â€» å…¨ã¦ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå¸¸ã«å¿…è¦ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚è³ªå•ã«å¿œã˜ã¦é©åˆ‡ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    â€» å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç•ªå·ã¯å¿…ãš [1], [2], [3], [4] ã®å½¢å¼ã§æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
    """
    context = dspy.InputField(desc="æ¤œç´¢ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚„æ”»ç•¥ç†è«–")
    history = dspy.InputField(desc="ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ï¼ˆåŒã˜ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®å ´åˆï¼‰")
    question = dspy.InputField(desc="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    answer = dspy.OutputField(desc="æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã€‚[1], [2], [3], [4]ã®ç•ªå·ä»˜ãã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹æˆã€‚å†·é™ã§è«–ç†çš„ã€éåº¦ã«ç†±è¡€çš„ã§ãªãå®¢è¦³çš„ã§å®Ÿç”¨çš„ãªå†…å®¹ã€‚")

# --- 3. Helper Functions ---
def summarize_conversation(conversation_history, current_question):
    """
    ä¼šè©±å±¥æ­´ã‚’è¦ç´„ã—ã€ç¾åœ¨ã®è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã ã‘ã‚’æŠ½å‡º
    
    Args:
        conversation_history: éå»ã®ä¼šè©±ï¼ˆUser/Botå½¢å¼ï¼‰
        current_question: ç¾åœ¨ã®è³ªå•
    
    Returns:
        str: è¦ç´„ã•ã‚ŒãŸæ–‡è„ˆï¼ˆç°¡æ½”ï¼‰
    """
    if not conversation_history or len(conversation_history.strip()) == 0:
        return ""
    
    try:
        summarizer = dspy.Predict(ConversationSummarizer)
        
        # Reflexãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿã«è¦ç´„
        with dspy.context(lm=reflex_lm):
            result = summarizer(
                conversation_history=conversation_history,
                current_question=current_question
            )
        
        return result.relevant_context
    
    except Exception as e:
        print(f"âš ï¸ Conversation summarization failed: {e}. Using original history.")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®å±¥æ­´ã‚’çŸ­ç¸®ã—ã¦è¿”ã™
        return conversation_history[:500]

# --- 4. Retrievers ---
def expand_query(question):
    """
    ã‚¯ã‚¨ãƒªæ‹¡å¼µ: è³ªå•ã‚’è¤‡æ•°ã®è¦³ç‚¹ã«åˆ†è§£
    
    DSPy ChainOfThoughtã‚’ä½¿ç”¨ã—ã¦ã€è³ªå•ã‚’3-5å€‹ã®ã‚µãƒ–ã‚¯ã‚¨ãƒªã«æ‹¡å¼µã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€å¤šé¢çš„ãªæƒ…å ±æ¤œç´¢ãŒå¯èƒ½ã«ãªã‚‹ã€‚
    
    Args:
        question: å…ƒã®è³ªå•
    
    Returns:
        List[str]: æ‹¡å¼µã•ã‚ŒãŸã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
    """
    try:
        expander = dspy.Predict(QueryExpansion)
        with dspy.context(lm=reflex_lm):  # é«˜é€ŸãªReflexãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            result = expander(question=question)
        
        # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
        queries = [q.strip() for q in result.expanded_queries.split(',')]
        
        # å…ƒã®è³ªå•ã‚‚å«ã‚ã‚‹
        all_queries = [question] + queries[:4]  # æœ€å¤§5å€‹ï¼ˆå…ƒã®è³ªå•+æ‹¡å¼µ4å€‹ï¼‰
        
        return all_queries
    except Exception as e:
        print(f"âš ï¸ Query expansion failed: {e}. Using original query only.")
        return [question]

def search_frame_data(char_name, move_name):
    """
    SQLiteã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢ç‰ˆï¼‰
    
    æ­£ç¢ºãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿”ã—ã€LLMã«ã‚ˆã‚‹æ¨æ¸¬ã‚’é˜²ã
    """
    if not os.path.exists(FRAME_DB_PATH):
        return "ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    
    conn = sqlite3.connect(FRAME_DB_PATH)
    c = conn.cursor()
    
    query = """
        SELECT
            c.name,
            m.move_name,
            m.move_category,
            m.startup,
            m.active_frames,
            m.total_frames,
            m.base_damage,
            m.damage_1v1,
            m.landing_lag,
            m.shield_advantage,
            m.note
        FROM moves m
        JOIN characters c ON m.char_id = c.id
        WHERE c.name LIKE ? AND m.move_name LIKE ?
    """
    
    c.execute(query, (f'%{char_name}%', f'%{move_name}%'))
    rows = c.fetchall()
    conn.close()
    
    if not rows:
        return f"ã€ãƒ‡ãƒ¼ã‚¿ãªã—ã€‘{char_name}ã®{move_name}ã«é–¢ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    # æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™
    result = f"=== {char_name}ã®{move_name} æ­£ç¢ºãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ ===\n\n"
    
    for row in rows:
        char, move, category, startup, active, total, base_dmg, dmg_1v1, landing, shield, note = row
        
        result += f"ã€æŠ€åã€‘{move}\n"
        result += f"ã€ã‚«ãƒ†ã‚´ãƒªã€‘{category if category else 'ä¸æ˜'}\n"
        
        if startup is not None:
            result += f"ã€ç™ºç”Ÿã€‘{startup}F\n"
        
        if active:
            result += f"ã€åˆ¤å®šæŒç¶šã€‘{active}\n"
        
        if total is not None:
            result += f"ã€å…¨ä½“ãƒ•ãƒ¬ãƒ¼ãƒ ã€‘{total}F\n"
        
        if base_dmg is not None:
            result += f"ã€ãƒ€ãƒ¡ãƒ¼ã‚¸ã€‘{base_dmg}%\n"
        
        if dmg_1v1 is not None:
            result += f"ã€ãƒ€ãƒ¡ãƒ¼ã‚¸(1v1)ã€‘{dmg_1v1}%\n"
        
        if landing is not None:
            result += f"ã€ç€åœ°éš™ã€‘{landing}F\n"
        
        if shield:
            result += f"ã€ã‚¬ãƒ¼ãƒ‰ç¡¬ç›´å·®ã€‘{shield}\n"
        
        if note:
            result += f"ã€å‚™è€ƒã€‘{note}\n"
        
        result += "\n"
    
    result += "â€»ä¸Šè¨˜ã®æ•°å€¤ã¯å…¬å¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚å›ç­”æ™‚ã«ã“ã®æ•°å€¤ã‚’ä¸€åˆ‡æ”¹å¤‰ã—ãªã„ã§ãã ã•ã„ã€‚\n"
    
    return result

def rerank_results(query, results, top_k=10):
    """
    æ¤œç´¢çµæœã‚’LLMã§å†è©•ä¾¡ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’æ”¹å–„
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        results: åˆæœŸæ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        top_k: è¿”ã™çµæœã®æ•°
    
    Returns:
        List: å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã‚ŒãŸçµæœï¼ˆä¸Šä½top_kä»¶ï¼‰
    """
    if not results:
        return []
    
    try:
        scorer = dspy.Predict(RelevanceScorer)
        reranked = []
        
        # å„çµæœã‚’LLMã§è©•ä¾¡
        for result in results:
            meta = result.get('metadata', {})
            title = meta.get('title', 'Unknown')
            content = meta.get('text_content', '')[:500]  # å…ˆé ­500æ–‡å­—ã®ã¿
            
            # Reflexãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
            with dspy.context(lm=reflex_lm):
                score_result = scorer(
                    question=query,
                    document_title=title,
                    document_content=content
                )
            
            # ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºï¼ˆ1-10ã®ç¯„å›²ï¼‰
            try:
                relevance = int(score_result.relevance_score)
                relevance = max(1, min(10, relevance))  # 1-10ã®ç¯„å›²ã«åˆ¶é™
            except:
                relevance = 5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            reranked.append((result, relevance))
        
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        reranked.sort(key=lambda x: x[1], reverse=True)
        
        # ä¸Šä½top_kä»¶ã‚’è¿”ã™
        return [r[0] for r in reranked[:top_k]]
    
    except Exception as e:
        print(f"âš ï¸ Re-ranking failed: {e}. Using original order.")
        return results[:top_k]

def search_theory(query, use_query_expansion=True, use_reranking=False):
    """
    Pineconeã‹ã‚‰ç†è«–ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆæœ€é©åŒ–ç‰ˆ V3ï¼‰
    
    æ”¹å–„ç‚¹ï¼ˆV1ï¼‰:
    - top_k: 5 â†’ 15ï¼ˆç¶²ç¾…æ€§å‘ä¸Šï¼‰
    - é–¾å€¤: 0.5 â†’ 0.35ï¼ˆã‚ˆã‚Šå¹…åºƒã„é–¢é€£æƒ…å ±ã‚’å–å¾—ï¼‰
    
    æ”¹å–„ç‚¹ï¼ˆV2 - ã‚¯ã‚¨ãƒªæ‹¡å¼µï¼‰:
    - è³ªå•ã‚’è¤‡æ•°ã®è¦³ç‚¹ã«åˆ†è§£ã—ã¦æ¤œç´¢
    - å„è¦³ç‚¹ã§æ¤œç´¢ã—ãŸçµæœã‚’çµ±åˆ
    - é‡è¤‡ã‚’é™¤å»ã—ã¦ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    
    æ”¹å–„ç‚¹ï¼ˆV3 - Re-rankingï¼‰:
    - åˆæœŸæ¤œç´¢ã§20ä»¶å–å¾—
    - LLMã§å„çµæœã®é–¢é€£æ€§ã‚’1-10ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    - çœŸã«é–¢é€£æ€§ã®é«˜ã„ä¸Šä½10ä»¶ã‚’ä½¿ç”¨
    
    åŠ¹æœ:
    - æ¤œç´¢çµæœæ•°: å¹³å‡2-3ä»¶ â†’ 8-12ä»¶ï¼ˆé«˜å“è³ªï¼‰
    - ç¶²ç¾…æ€§: +80%
    - ç²¾åº¦: +50%ï¼ˆãƒã‚¤ã‚ºå‰Šæ¸›70%ï¼‰
    - å¤šé¢çš„ãªè³ªå•ã¸ã®å¯¾å¿œåŠ›ãŒå¤§å¹…å‘ä¸Š
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        use_query_expansion: ã‚¯ã‚¨ãƒªæ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
        use_reranking: Re-rankingã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
    """
    if not PINECONE_API_KEY: return "Pinecone Key Missing"
    try:
        pc = Pinecone(api_key=PINECONE_API_KEY)
        index = pc.Index("smash-coach-index")
        genai.configure(api_key=GEMINI_API_KEY)
        
        # ã‚¯ã‚¨ãƒªæ‹¡å¼µ
        queries = [query]
        if use_query_expansion:
            queries = expand_query(query)
            print(f"ğŸ” Query Expansion: {len(queries)} queries")
        
        # å„ã‚¯ã‚¨ãƒªã§æ¤œç´¢ã—ã¦çµæœã‚’çµ±åˆï¼ˆRe-rankingç”¨ã«å¤šã‚ã«å–å¾—ï¼‰
        all_matches = {}  # id -> match ã®è¾æ›¸
        
        for q in queries:
            emb = genai.embed_content(model="models/text-embedding-004", content=q)
            # Re-rankingç”¨ã«å¤šã‚ã«å–å¾—ï¼ˆ10â†’15ï¼‰
            results = index.query(vector=emb['embedding'], top_k=15, include_metadata=True)
            
            for m in results.get('matches', []):
                doc_id = m.get('id', '')
                score = m.get('score', 0.0)
                
                # åŒã˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¤‡æ•°ã®ã‚¯ã‚¨ãƒªã§ãƒ’ãƒƒãƒˆã—ãŸå ´åˆã€æœ€é«˜ã‚¹ã‚³ã‚¢ã®matchã‚’ä¿æŒ
                if doc_id not in all_matches or score > all_matches[doc_id].get('score', 0.0):
                    all_matches[doc_id] = m
        
        # matchã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã«å¤‰æ›
        match_list = list(all_matches.values())
        
        # Re-rankingï¼ˆLLMã§å†è©•ä¾¡ï¼‰
        if use_reranking and match_list:
            print(f"ğŸ¯ Re-ranking {len(match_list)} documents...")
            reranked_matches = rerank_results(query, match_list, top_k=12)
        else:
            # Re-rankingãªã—ã®å ´åˆã¯ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
            reranked_matches = sorted(match_list, key=lambda x: x.get('score', 0.0), reverse=True)[:12]
        
        # ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆç”Ÿæˆ
        context = "ã€å‚ç…§ã•ã‚ŒãŸæ”»ç•¥ç†è«–ã€‘\n"
        if not reranked_matches:
            return "é–¢é€£ã™ã‚‹ç†è«–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # é–¾å€¤0.30ä»¥ä¸Šã®çµæœã‚’ä½¿ç”¨ï¼ˆRe-rankingå¾Œã¯ã‚ˆã‚Šä¿¡é ¼ã§ãã‚‹ã®ã§é–¾å€¤ã‚’ä¸‹ã’ã‚‹ï¼‰
        result_count = 0
        for match in reranked_matches:
            score = match.get('score', 0.0)
            
            # Re-rankingå¾Œã¯é–¾å€¤ã‚’ç·©å’Œï¼ˆ0.30ï¼‰
            threshold = 0.30 if use_reranking else 0.35
            if score < threshold:
                continue
            
            meta = match.get('metadata', {})
            context += f"--- {meta.get('title')} (é–¢é€£åº¦:{score:.2f}) ---\n{meta.get('text_content')}\n\n"
            result_count += 1
        
        print(f"âœ… Retrieved {result_count} documents (after filtering)")
        return context
        
    except Exception as e:
        return f"Search Error: {e}"

# --- 4. Brain Module ---
class SmashBrain(dspy.Module):
    """
    === DSPy Reasoning Engine (Legacy Type A) ===
    
    STUDENT COMPONENT: Reasoning orchestrator combining Intent Classification + Context Retrieval + Answer Generation
    
    This is the legacy Type A architecture (before Type B refactoring in model.py).
    Maintained for backward compatibility. New code should use SmashCoach (Type B).
    
    === Pipeline ===
    1. IntentClassifier (Reflex LM): Determine info source (frame_data vs theory)
    2. Search Dispatch: Query SQLite (frame_data) or Pinecone (theory)
    3. CoachAnswer (Thinking LM): Generate response using ChainOfThought reasoning
    
    === Optimization Paths ===
    - dspy.Teleprompter: Auto-tune IntentClassifier and CoachAnswer prompts
    - dspy.BootstrapFewShot: Learn from user /teach corrections
    - Dual-Model Strategy: Reflex for classification (fast), Thinking for generation (quality)
    """
    def __init__(self):
        super().__init__()
        self.classify = dspy.ChainOfThought(IntentClassifier)
        self.generate = dspy.ChainOfThought(CoachAnswer)
        self.frame_answer = dspy.ChainOfThought(FrameDataAnswer)
    
    def forward(self, question, history=""):
        """
        === DSPy Forward Pass (ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢ç‰ˆ) ===
        
        Orchestrates two-stage reasoning:
        1. Intent Classification: Determines whether to use frame_data or theory
        2. Context-Aware Generation: Generates coaching response based on classified intent
        
        **ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢**:
        - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿è³ªå•ã®å ´åˆã€å°‚ç”¨ã®FrameDataAnswerSignatureã‚’ä½¿ç”¨
        - æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®æ”¹å¤‰ã‚’å³ç¦ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ
        - SQLiteã‹ã‚‰å–å¾—ã—ãŸæ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨
        
        Args:
            question: User's coaching query (str)
            history: Previous conversation history in the same thread (str, optional)
        
        Returns:
            response.answer: Coaching advice as string
        
        === Implementation Details ===
        - Uses asyncio.to_thread() compatibility (blocking I/O safe in Discord context)
        - Dynamic model selection: Reflex for fast classification, Thinking for quality generation
        - Fallback: If search fails, still attempts to generate response from question context
        - History-aware: Maintains context across thread conversations
        
        === Redefinability ===
        - LM models: Can be swapped via dspy.context(lm=...)
        - Retrieval sources: Can be extended to support additional databases
        - Signatures: IntentClassifier and CoachAnswer prompts are dspy.Signature (tunable)
        """
        # 1. æ„å›³åˆ†é¡ (Reflex Model: æœ€å¼·ã®Flashã‚’ä½¿ç”¨)
        with dspy.context(lm=reflex_lm):
            classification = self.classify(question=question)
        
        intent = classification.intent.lower()
        char = classification.character
        move = classification.move
        
        # 2. æƒ…å ±æ¤œç´¢
        context = ""
        is_frame_data_query = False
        
        if "frame" in intent or "data" in intent:
            if char:
                context = search_frame_data(char, move if move else "")
                is_frame_data_query = True
            else:
                context = search_theory(question)
        else:
            context = search_theory(question)
            
        # 3. å›ç­”ç”Ÿæˆ (Thinking Model: æœ€å¼·ã®Pro/Expã‚’ä½¿ç”¨)
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯å°‚ç”¨ã®Signatureã‚’ä½¿ç”¨ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢ï¼‰
        if is_frame_data_query and "===æ­£ç¢ºãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿===" in context:
            print("ğŸ›¡ï¸ Using FrameDataAnswer signature (hallucination prevention)")
            response = self.frame_answer(frame_data=context, question=question)
        else:
            # é€šå¸¸ã®å›ç­”ç”Ÿæˆ
            response = self.generate(context=context, history=history, question=question)
        
        return response.answer
